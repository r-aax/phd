% Векторизация.
\newpage
\section*{Глава 5. Векторизация вычислений} % выключить номер главы
\addcontentsline{toc}{section}{Глава 5. Векторизация вычислений} % но добавить ее в оглавление
\setcounter{section}{5}                                                    % а теперь и счетчик продвинуть
\setcounter{subsection}{0}
\setcounter{figure}{0}
\setcounter{equation}{0}
\setcounter{table}{0}
\setcounter{theorem}{0}
\setcounter{lemma}{0}
\setcounter{definition}{0}

% Описательная часть про векторизацию.
Векторизация вычислений это низкоуровневая оптимизация, применение которой способно кратно повысить производительность программного кода и сократить энергопотребление \cite{Cebrian2019VecScal}.
Использование векторных инструкций позволяет применять одинаковые операции сразу к нескольким наборам входных данных, упакованных в векторные регистры.
Векторные инструкции представлены во многих современных микропроцессорным архитектурах, но в наибольшей степени они развиты в архитектуре x86.

% x86
Архитектура x86 представлена богатым набором векторных инструкций, которые добавлялись постепенно по мере развития \cite{IntelSDM2025}.
Первый набор инструкций MMX\label{abbr:mmx-1} был предназначен для обработки аудио и видеоданных и содержал операции по работе с целыми числами, упакованными в 64-битные регистры.
В дальнейшем в архитектуру были добавлены несколько наборов SSE\label{abbr:sse-1} и AVX\label{abbr:avx-2} инструкций, и наконец AVX-512 с возможностью выборочной обработки элементов векторов.

Упомянем кратко другие микропроцессорные архитектуры, в которых можно встретить поддержку векторных вычислений.

% ARM
В архитектуре ARM\label{abbr:arm-1} векторные инструкции поддержаны в 128-битном SIMD\label{abbr:simd-1} расширении Neon, и они являются по сути аналогом SSE инструкций в x86 \cite{Zhuykov2012VecARM}.
Инструкции Neon поддерживают работу с целыми элементами данных размера от 8 до 64 битов, а также с вещественными значениями размера 16, 32 и 64 бита.
Инструкции Neon не поддерживают выборочную обработку элементов данных векторов, однако в наборе предусмотрены широкие возможности комбинирования данных путем выполнения операций сдвига и перестановки элементов внутри вектора.
Современное расширение SVE\label{abbr:sve-1} \cite{Stephens2017VecARM} позволяет оперировать терминами векторных вычислений без привязки к конкретной длине вектора (при условии кратности 128), которая определяется аппаратной реализацией.
В частности, в микропроцессоре Fujitsu A64FX используется набор SVE инструкций с реализаций длины вектора 512-бит \cite{Okazaki2020A64FX}.

% Power
Для поддержки векторных и матричных вычислений в архитектуре Power предусмотрено векторное расширение VMX\label{abbr:vmx-1} \cite{Eisen2007VecPower}.
Расширение поддерживает векторные регистры, состоящие из целых значений размера до 32 битов, либо вещественные значения одинарной точности.
В расширение входят арифметические и логические операции, операции доступа в память, однако выборочная обработка элементов векторов не поддержана.

% Эльбрус
В архитектуре <<Эльбрус>> присутствует поддержка векторных операций для коротких векторов размера 64 бита, что позволяет паралльно выполнять арифметические операции над элементами векторов \cite{Ishin2011VecElbrus}.
Так как выборочная обработка элементов векторов в этом наборе инструкций также отсутствует, то для векторизации управления в цикле используются логические операции обнуления ненужных частей соответствующих векторных регистров с последующим их слиянием \cite{Volkonsky2012VecElbrus}.

% Китайские.
Можно отметить современные китайские микропроцессорные архитектуры, также поддерживающие векторизацию.
Так, в оригинальной архитектуре LoongArch, на базе которой создан микропроцессор Loongson 3A6000, поддержаны векторные инструкции, работающие с упакованными векторами размера 128 и 256 бит \cite{Bai2024VecLoongarch}.
А в архитектуре Sunway \cite{Sun2023VecSunway}, на базе которой собрана одна из мощнейших линеек китайских суперкомпьютеров, в систему команд включены инструкции для работы с 512-битными векторами.

Для оценки качества векторизации программного кода в этой главе будем использовать следующие понятия.

\begin{definition}
Шириной векторизации назовем величину $w = \frac{v}{t}$, где $v$ -- размер векторного регистра, $t$ -- размер типа расчетных данных.
\end{definition}

То есть, например, при выполнении расчетов на вещественных данных одинарной точности (float, размер 32 бита) ширина векторизации при использовании AVX-512\label{abbr:avx-3} (размер векторного регистра 512 битов) равна 16.

\begin{definition}
Ускорением программного кода от векторизации будем называть величину $s_{vec} = \frac{T}{T_v}$, где $T$ -- время выполнения скалярной версии кода, $T_v$ -- время выполнения векторной версии кода.
\end{definition}

\begin{definition}
Эффективностью векторизации будем называть величину $e_{vec} = \frac{s_{vec}}{w}$.
\end{definition}

Эффективность векторизации является удобной мерой сравнения векторного кода.
Значение $e_{vec}$ может превышать единицу при использовании, например, большого количества векторных FMA\label{abbr:fma-1} операций.
Однако, в большинстве случаев этот показатель меньше единицы.

\begin{definition}
Логическим ускорением программного кода от векторизации будем называть величину $s_{vec}^{*} = \frac{L}{L_v}$, где $L$ -- количество выполненных инструкций в скалярном коде, $L_v$ -- количество выполненных аналогичных им инструкций в векторном коде (будем считать, что в идеальном случае $w$ одинаковых скалярных инструкций объединяются в одну аналогичную векторную инструкцию, и $s_{vec}^{*} = w$).
\end{definition}

\begin{definition}
Логической эффективностью векторизации будем называть величину $e_{vec}^{*} = \frac{s_{vec}^{*}}{w}$.
\end{definition}

%---------------------------------------------------------------------------------------------------
% 5.1 - AVX-512

\subsection{Векторные инструкции AVX-512}\label{abbr:avx-4}

Наиболее продвинутым набором векторных инструкций является AVX-512, поддержку которого можно встретить в микропроцессорах Intel и AMD\label{abbr:amd-1}.
Инструкции AVX-512 работают с векторными регистрами zmm размера 512 бит, каждый из которых вмещает в себя 8 элементов в формате вещественных чисел двойной точности, что с учетом комбинированных операций приводит к возможности выполнения 16 операций сложения и умножения двойной точности за одну векторную команду.
Из этого следует, что на микропроцессорах с поддержкой AVX-512 без использования векторизации даже теоретически невозможно добиться производительности более 6,25\% от пиковой производительности.
Особенности векторных инструкций AVX-512 позволяют применять их для векторизации достаточно сложного программного контекста, однако оптимизирующий компилятор не всегда успешно справляется с этой задачей.
Для обеспечения программисту возможности прямого использования векторных инструкций существует набор функций-интринсиков \cite{IntelIntrinsicsGuide}, которые в дальнейшем заменяются компилятором на конкретные векторные инструкции или последовательности инструкций.
Интринсики упрощают разработку векторизованного кода и позволяют вести разработку в терминах функций, применяемых к векторным данным.

Можно считать, что впервые AVX-512 был поддержан в 2016 году в микропроцессорах Intel Xeon Phi KNL\label{abbr:knl-5} \cite{Jeffers2016KNL}, так как более раннее поколение Intel Xeon Phi Knights Corner (KNC)\label{abbr:knc-1} представляет собой ускоритель, и векторный код для него не является x86 совместимым.

\subsubsection{Обзор применения инструкций AVX-512}

Отметим актуальные работы, в которых приведены результаты по ускорению программных кодов, полученные с помощью векторизации.

В работе \cite{Kulikov2019VecAstro} путем векторизации безусловных операций продемонстрировано повышение производительности газодинамического решателя на 200\%.
В работе \cite{Glinting2019VecSwim} описывается сравнение реализации римановских решателей в применении к теории мелкой воды, одним из результатов работы является ускорение решателя с помощью инструкций AVX-512 в 16,7 раз при работе с вещественными числами одинарной точности.
В исследовании \cite{Yildirim2021VecCFD} было достигнуто ускорение в 3,27 газодинамического решателя ADflow, работающего на структурированных расчетных сетках.
Ускорение достигнуто путем декомпозиции сетки на вычислительные блоки, которые могут быть эффективно обработаны с точки зрения использования кэш-памяти и применения векторных инструкций AVX-512.
В работе \cite{Rucci2020VecNBody} рассмотрена реализация расчета гравитационного взаимодействия между $N$ телами, из результатов видно, что использование набора инструкций AVX-512 позволило ускорить работу приложения в 2 и более раз.
В работе \cite{Rucci2019VecSW} авторы успешно применили векторные инструкции в задаче поиска сходных участков в белковых последовательностях.
%Работы \cite{Choi2023VecKorean,Cheng2021VecCSIDH} посвящены ускорению алгоритмов, связанных с шифрованием.
В работе \cite{Blacher2022VecQuick} предложена векторная версия быстрой сортировки (vqsort), превышающая по эффективности реализацию из стандартной библиотеки (qsort) более чем в 10 раз.
В работе \cite{Long2022VecSPD} рассматриваются реализация бессеточного метода решения задачи газовой динамики и векторизация этого метода, использование векторных инструкций AVX-512 позволило ускорить исходный код в 6,3 раза.
В статье \cite{PonteFernandez2022VecInteractions} векторизация применяется для алгоритма анализа генетических вариаций, использование AVX-512 позволило добиться ускорения расчетов от 7 до 12 раз по сравнению с оригинальным алгоритмом.
В работе \cite{Quisland2023VecSeries} рассматривается прямое применение инструкций AVX-512 для задачи обработки временных рядов, что привело к ускорению результирующего кода в 4 раза по сравнению с автоматической векторизацией, выполняемой оптимизирующим компилятором. 
Статья \cite{Buhrow2022VecMult} посвящена оптимизации алгоритмов шифрования с открытым ключом, в частности, рассматривается оптимизация блочного варианта умножения Монтгомери.
Было достигнуто ускорение основных операций от 1,5 до 1,9 раза.
В статье \cite{Choi2022VecPIPO} показана реализация алгоритма блочного шифрования на различных архитектурах, включая GPU\label{abbr:gpu-1} и CPU\label{abbr:cpu-1}, использование AVX-512 позволило ускорить его в 9,5 раза по сравнению с оригиналом.
В статье \cite{Cheng2022VecSIKE} рассматривается применение векторных инструкций для оптимизации математических операций, используемых в протоколе обмена ключами с применением суперсингулярных изогений (SIKE)\label{abbr:sike-1}, в результате выполненных усовершенствований зафиксировано ускорение отдельных операций в диапазоне от 1,5 до 3,5 раза.
В работе \cite{Sansone2023VecFourier} векторизация с помощью AVX-512 применяется для оптимизации быстрого преобразования Фурье, что привело к ускорению примерно в полтора раза по сравнению с оригинальной версией.
Работа \cite{Edamatsu2023VecDiv} посвящена применению подмножества инструкций Integer Fused Multiply-Add (AVX-512 IFMA)\label{abbr:ifma-1} для повышения эффективности реализации деления больших целых чисел, в результате оптимизации было достигнуто ускорение функционала на 25–35\%.
В работе \cite{Medakin2021VecPP} продемонстрирован практический подход к векторизации расчета попарного взаимодействия множества частиц, использование инструкций AVX-512 в явном виде привело к ускорению исполнения программы в 3,3 раза.
В статье \cite{Tayeb2023VecAuto} предлагается подход к развитию средств автоматической векторизации расчетных циклов, основанный на анализе и эквивалентных преобразованиях графа зависимостей между операциями, расположенными в теле цикла.
Этот подход позволяет переупорядочить операции внутри цикла, снизив их количество и укоротив критический путь исполнения \cite{Laukemann2019VecAuto}, и сгруппировать для объединения в векторные инструкции.

В качестве практического руководства по созданию векторизованного программного кода с помощью функций-интринсиков для языка программирования C++ и с помощью языка ассемблера для широкого спектра практических задач, включая задачи линейной алгебры, обработки изображений, реализацию сверток и другие, можно рассматривать работу \cite{Kusswurm2022VecCpp}.

\subsubsection{Особенности инструкций AVX-512}

Множество инструкций AVX-512\label{abbr:avx-5} состоит из нескольких подмножеств, их перечень расширяется с появлением новых поколений микропроцессоров (при этом в различных поколениях микропроцессоров поддержаны разные наборы подмножеств инструкций AVX-512) \cite{IntelSDM2025}.

AVX-512 F (Foundation) -- основной набор, который содержит в себе базовые операции для работы с векторными данными, включая арифметику, операции конвертации, сравнения, операции перестановки элементов векторов и другие.

Набор AVX-512 VL\label{abbr:vl-1} (Vector Length) позволяет расширить многие векторные инструкции для работы со 128-битными XMM регистрами и 256-битными YMM регистрами на длину вектора 512.

Набор AVX-512 BW\label{abbr:bw-1} (Byte and Word) расширяет инструкции для работы с элементами векторов размера 8 и 16 бит, а AVX-512 DQ\label{abbr:dq-1} (Doubleword and Quadword) добавляет новые инструкции, работающие с элементами размера 32 и 64 бита.

Набор AVX-512 CD\label{abbr:cd-1} (Conflict Detection) содержит операцию для нахождения пар совпадающих целых значений в двух векторах (VPCONFLICTD/Q), а также операции записи маски в элементы вектора и подсчета количества ведущих нулей в элементах вектора.
Операции подсчета количества единиц в элементах векторов определены в наборах AVX-512 BITALG\label{abbr:bitalg-1} (Bit Algorithms) и AVX-512 VPOPCNTDQ (Vector population count).

AVX-512 ER\label{abbr:er-1} (Exponential and Reciprocal) включает в себя инструкции для вычисления значений $2^x$, $1/x$, $1/{x^2}$.

AVX-512 PF\label{abbr:pf-1} (PreFetch) содержит операции предварительной подкачки данных для VGATHERDPS/VSCATTERDPD, что позволяет уменьшить вероятность промаха в кэш при дальнейших обращениях в память.

Наборы AVX-512 VBMI\label{abbr:vbmi-1} (Vector Byte Manipulation Instructions) и AVX-512 VBMI2 добавляют новые операции, работающие с 8-битными данными, такие как перестановка элементов, чтение из памяти и запись в память, конкатенация со сдвигом.

AVX-512 IFMA\label{abbr:ifma-2} (Integer Fused Multiply Add) содержит комбинированные операции над целыми числами, которые используются для реализации работы с большими числами или для шифрования \cite{Edamatsu2023VecDiv}.

Набор AVX-512 FP16\label{abbr:fp-1} включает в себя арифметические операции и операции конвертации для работы с вещественными числами половинной точности, а набор AVX-512 BF16\label{abbr:bf-1} добавляет инструкции для работы с форматом brain float 16 \cite{Kalamkar2019VecBF16}.

AVX-512 VNNI\label{abbr:vnni-1} (Vector Neural Network Instructions) и AVX-512 4VNNIW\label{abbr:vnniw-1} содержат операции поэлементного перемножения пар целых чисел с последующим их сложением.
Операции выполняются над 8-битными и 16-битными данными и используются в задачах линейной алгебры, в частности для реализации искусственных нейронных сетей \cite{Zhou2024VecVNNI}.
Набор AVX-512 4FMAPS\label{abbr:fmaps-1} (Fused Multiply Accumulation Packed Single) содержит инструкции V4FMADDPS и V4FNMADDPS, реализующие комбинированные операции над четырьмя 512-битными операндами и значениями из памати, объединяя в себе 64 операции перемножения и 64 операции сложения 16-битных вещественных чисел.

AVX-512 VPCLMULQDQ содержит операцию VPCLMULQDQ, предназначенную для перемножения 128-битных целых чисел.

AVX-512 VP2INTERSECT (Vector pair intersection) содержит операции VP2INTERSECTD и VP2INTERSECTQ, используемые для определения пересечений двух векторов 32-битных или 64-битных целых чисел \cite{DiezCanas2021VecVP2Int}.

AVX-512 VAES\label{abbr:vaes-1} (Vector Advanced Encryption Standard) содержит векторные операции для поддержки алгоритма блочного шифрования \cite{Kovats2024VecAES}.

AVX-512 GFNI\label{abbr:gfni-1} (Galois Field New Instructions) включает в себя операции для работы в конечном поле Галуа $GF(2^8)$\label{abbr:gf-1}, использование которых распространено для реализации алгоритмов шифрования \cite{Yoo2023VecGFNI}.

Для поддержки выборочного применения операций над упакованными данными к конкретным элементам векторов большинство инструкций AVX-512\label{abbr:avx-6} использует специальные регистры-маски (k0 -- k7) в качестве аргументов.
Маски используются в командах для осуществления условной операции над элементами упакованных данных (если соответствующий бит выставлен в 1, то результат операции записывается в соответствующий элемент вектора назначения) или для слияния элементов данных в регистр назначения.
Также маски могут использоваться для выборочного чтения из памяти и запись в память элементов векторов, для аккумулирования результатов логических операций над элементами векторов.
Эта уникальная особенность набора инструкций AVX-512 обеспечивает реализацию предикатного режима исполнения \cite{Volkonsky2003VecPred}, который поддержан в таких архитектурах, как ARM\label{abbr:arm-2} или «Эльбрус» \cite{Kim2013VecElb}.
Наличие предикатного режима исполнения позволяет применять оптимизацию слияния ветвей исполнения и, таким образом, избавляться от лишних операций передачи управления, что помогает создавать высокоэффективный параллельный код.

Из других важных особенностей набора инструкций AVX-512 можно отметить операции множественного чтения элементов векторов, расположенных в памяти с произвольными смещениями от базового адреса, а также аналогичные операции записи элементов векторов в память с произвольными смещениями (операции gather/scatter).
Хотя эти операции крайне медленные, они в некоторых случаях помогают существенно упростить логику векторизованного кода.
Также следует отметить большое разнообразие операций перестановки, перемешивания, дублирования, пересылки элементов векторов, что позволяет произвольным образом менять порядок обработки данных.
Также существенное ускорение способны принести комбинированные операции, объединяющие операцию умножения и сложения в одну операцию.

%По схеме работы можно выделить несколько групп операций AVX-512.
%Упакованные операции с одним, двумя или тремя операндами zmm (512-битный вектор) и одним результатом zmm получают на вход один, два или три вектора и поэлементно применяют определенную функцию, получая результат того же размера, который по маске записывается в выходной вектор.
%Примерами таких операций являются арифметические операции, включая упакованные, вычисляющие значения вида $\pm a \cdot b \pm c$.
%Операции конвертации предназначены для преобразования элементов вектора из одного формата в другой, к ним относятся наборы команд cvt и pack.
%Операции перестановок не выполняют арифметических действий, а только переставляют части вектора в произвольном порядке, определяемом типом операции и дополнительными параметрами (операции unpck, shuf, align, blend, perm).
%Операции пересылок предназначены для перемещения последовательных данных между регистрами, а также между памятью и регистром.
%Поддержаны также операции пересылки элементов данных, расположенных не последовательно, а с произвольными смещениями от заданного базового адреса в памяти (операции gather и scatter), а также операции пересылки с дублированием элементов.
%Операции предварительной подкачки данных используются для того, чтобы увеличить вероятность того, что к моменту исполнения команды данные уже будут в кэше.
%Кроме того, поддержаны другие операции с более сложной логикой, среди которых определение класса вещественного числа, реализация логических функций от трех аргументов, операции определения конфликтов и другие

Для упрощения применения векторных инструкций при оптимизации программного кода, написанного на языке C/C++, разработаны специальные функции-интринсики \cite{IntelIntrinsicsGuide}.
Эти функции покрывают не все множество инструкций AVX-512, однако избавляют от необходимости вручную писать ассемблерный код.
Вместо этого предоставляется возможность оперировать встроенными типами данных для 512-битных векторов и использовать их при работе с функциями-инстринсиками как обычные базовые типы (при построении компилятором исполняемого кода для этих типов данных будут использованы регистры zmm).
Некоторые функции-инстринсики соответствуют не одной отдельной команде, а целой последовательности, как, например, группа функций reduce, другие же просто раскрываются в вызов библиотечной функции (например, тригонометрические функции).

В этой главе рассмотрены различные подходы и методы векторизации программного кода, как с помощью оптимизирующего компилятора, так и с помощью явного использования функций-интринсиков.
При этом в некоторых листингах по тексту главы некоторые имена интринсиков сокращаются, где это не мешает пониманию: например, при рассмотрении операций с вещественными числами одинарной точности вместо имени интринсика \texttt{\_mm512\_add\_ps} может быть использовано просто обозначение \texttt{ADD}.

%---------------------------------------------------------------------------------------------------
% 5.2 - выделение однотипных операций

\subsection{Векторизация с помощью выделения однотипных \mbox{операций}}\label{sec:text_4_small_matr}

Так как основной смысл векторной команды состоит в поэлементной обработке векторных данных с помощью одной и той же операции, то для выполнения векторизации необходимо выделить в коде однотипные операции, которые далее могут быть объединены в векторные команды.
В качестве примера программного контекста для анализа этого подхода будем рассматривать операции над матрицами малой размерности \cite{Bendersky2018VecMat2}.

\subsubsection{Операции с малоразмерными матрицами}\label{sec:vec_small_matr_opers}

Будем рассматривать следующие операции: умножение матрицы размера $8 \times 8$ на вектор, перемножение двух матриц размера $8 \times 8$, нахождение обратной матрицы размера $8 \times 8$.

\begin{singlespace}
\begin{lstlisting}[caption={Невекторизованная версия умножения матрицы \\ размера $8 \times 8$ на вектор.},label={lst:text_4_small_matr_8x8_mul_vel_noopt}]
void matvec8_orig(float* __restrict m,
                  float* __restrict v,
                  float* __restrict r)
{
    for (int i = 0; i < V8; ++i)
    {
        float sum = 0.0;
        int ii = i * V8;

        for (int j = 0; j < V8; ++j) sum = sum + m[ii + j] * v[j];
        r[i] = sum;
     }
}
\end{lstlisting}
\end{singlespace}

Реализация скалярной версии умножения матрицы $8 \times 8$ на вектор представлена на листинге~\ref{lst:text_4_small_matr_8x8_mul_vel_noopt}.
Матрица $m$ хранится в сплошной области памяти по строкам.
Параметры функции передаются c указанием \texttt{\_\_restrict} для облегчения компилятору задачи по оптимизации.
Умножение матрицы $m$ на вектор $v$ состоит в вычислении скалярного произведения строк матрицы на вектор и составлении из результатов выходного вектора $r$.
Размер строки матрицы равен 8 элементам типа float, то есть одной операцией в 512-битный регистр можно загрузить сразу 2 ее соседние строки.
Далее нужно выполнить операцию упакованного умножения на регистр, содержащий две копии $v$.
Сумма первых восьми элементов получившегося регистра и последних восьми элементов будут являться элементами выходного вектора $r$ (см. рис.~\ref{fig:text_4_small_matr_matvec8}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./fig/vec_matvec8.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычисления результата в операции \texttt{matvec8}.}
\label{fig:text_4_small_matr_matvec8}
\end{figure}

При реализации операции умножения матрицы $m$ на вектор $v$ загрузим всю матрицу в четыре zmm регистра и умножим их на регистр, содержащий две копии $v$.
Из получившихся четырех регистров получим сумму элементов каждой его половины, что в результате даст 8 искомых элементов выходного вектора $r$.
Получение суммы элементов половины zmm регистра представляет собой горизонтальную операцию, реализация которой с помощью интринсика оказывается слишком дорогой.
Как показали эксперименты, простое применение интринсика \texttt{\_mm512\_mask\_reduce\_add\_ps} (и даже безмасочного \texttt{\_mm512\_reduce\_add\_ps} в случае умножения матрицы $16 \times 16$) не приводит к ускорению по сравнению с оригинальной версией функции, оптимизированной компилятором icc с использованием уровня оптимизации -O3.
Прежде чем переходить к оптимизации горизонтальных операций сложения рассмотрим второй пример, -- перемножение двух матриц размера $8 \times 8$, -- с целью выделения похожих однотипных операций.

%Как и в случае с примером умножения матрицы на вектор, вначале приведем простую реализацию неоптимизированной версии перемножения двух матриц размера $8 \times 8$ (листинг~\ref{lst:text_4_small_matr_8x8_mul_matr_noopt}):

Логика перемножения двух матриц состоит в том, что результаты попарного скалярного произведения 8 строк первой матрицы и 8 столбцов второй матрицы формируют элементы результирующей матрицы.
Как и в случае умножения матрицы на вектор, использование 512-битных команд загрузки данных из памяти позволяет за одну операцию загрузить две соседние строки первой матрицы (операцией последовательного чтения) или два соседних столбца второй матрицы (с помощью операции gather).
После этого нужно вычислить скалярные произведения каждой половины загруженного из первой матрицы вектора с каждой половиной загруженного из второй матрицы вектора.
Для этого выполняются две операции поэлементного перемножения двух загруженных векторов, в одном из которых старшая и младшая половины второго вектора переставлены местами, как показано на рис.~\ref{fig:text_4_small_matr_matmat8}.

%\begin{singlespace}
%\begin{lstlisting}[caption={Невекторизованная версия перемножения матриц \\ размера $8 \times 8$.}, label={lst:text_4_small_matr_8x8_mul_matr_noopt}]
%void matmat8_orig(float* __restrict a,
%                  float* __restrict b,
%                  float* __restrict r)
%{
%    for (int i = 0; i < V8; ++i)
%    {
%        int ii = i * V8;
% 
%        for (int j = 0; j < V8; ++j)
%        {
%            float sum = 0.0;
%
%            for (int k = 0; k < V8; ++k)
%            {
%                int kk = k * V8;
%                
%                sum = sum + a[ii + k] * b[kk + j];
%            }
%
%            r[ii + j] = sum;
%        }
%    }
%}
%\end{lstlisting}
%\end{singlespace}

\begin{figure}[ht]
\centering
\includegraphics[width=1.00\textwidth]{./fig/vec_matmat8.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычисления результата в операции \texttt{matmat8}.}
\label{fig:text_4_small_matr_matmat8}
\end{figure}

После выполнения действий, представленных на рис.~\ref{fig:text_4_small_matr_matmat8}, возникает потребность вычисления суммы 8 младших элементов вектора и 8 старших элементов этого же вектора.
Таким образом, мы приходим к тому, что каждый элемент результирующей матрицы должен быть получен с помощью горизонтальной операции суммирования 8 младших или старших элементов некоторого zmm регистра.

Примеры реализаций функций \texttt{matvec16\_orig} и \texttt{matmat16\_orig} аналогичны, но там возникают задачи суммирования всех 16 элементов вектора.
Отсюда возникает потребность объединения таких горизонтальных операций вместе.
Рассмотрим задачу в общем виде: даны 16 zmm регистров ($a$, $b$, $c$, $d$, $e$, $f$, $g$, $h$, $i$, $j$, $k$, $l$, $m$, $n$, $o$, $p$), каждый из которых содержит по 16 элементов типа float.
Требуется посчитать суммы их элементов и записать в один регистр zmm.
Набор команд AVX-512\label{abbr:avx-7} и библиотека интринсиков содержат все необходимые возможности для эффективной реализации этого функционала.
Схема вычислений состоит из четырех фаз, каждая из которых реализуется операциями перестановок с последующим сложением и слиянием векторов.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.95\textwidth]{./fig/vec_horizontal_add.pdf}
\singlespacing
\captionstyle{center}\caption{Схема суммирования элементов zmm вектора.}
\label{fig:text_4_small_matr_horizontal_add}
\end{figure}

На рис.~\ref{fig:text_4_small_matr_horizontal_add} представлена схема суммирования элементов пары векторов.
Набор команд AVX-512 не содержит операций горизонтального сложения элементов вектора zmm.
Будем реализовывать сложение двух элементов одного и того же вектора с помощью покомпонентного сложения этого вектора со своей копией, в которой элементы переставлены нужным образом.
Это действие и выполняется на каждой обозначенной на рис.~\ref{fig:text_4_small_matr_horizontal_add} фазе.
Так как всего вектор содержит 16 элементов, то минимальное количество фаз, необходымых для суммирования его элементов равно 4.
После первой фазы (после выполнения операции слияния blend) можно наблюдать вектор, содержащий суммы пар соседних элементов векторов $a$ и $b$, после второй фазы вектор состоит уже из сумм четверок элементов векторов $a$ -- $d$, после третьей фазы вектор содержит суммы 8 элементов векторов $a$ -- $h$, а после четвертой фазы вектор содержит суммы всех элементов векторов $a$ -- $p$.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./fig/vec_horizontal_add_operations_tree.pdf}
\singlespacing
\captionstyle{center}\caption{Схема суммирования элементов 16 zmm векторов.}
\label{fig:text_4_small_matr_operations_tree}
\end{figure}

На рис~\ref{fig:text_4_small_matr_operations_tree} представлен граф потока данных для суммирования всех элементов 16 векторов.
Черными квадратами обозначены операции перестановки элементов (swizzle или permute в терминах интринсиков), черными кругами -- операции сложения вектора со своей пермутированной копией, а белые круги обозначают операции слияния двух векторов по маске.
Прямоугольниками с пунктирной границей очерчены стадии из рис.~\ref{fig:text_4_small_matr_horizontal_add}.

Граф потока данных на рис.~\ref{fig:text_4_small_matr_operations_tree} состоит из схожих блоков операций: 2 swizzle/permute + 2 add + 1 blend.
Причем на каждой фазе свои маски перестановок и слияний, но они постоянны для всех входных векторов.
Для удобства можно определить макросы, реализующие обозначенные фазы.
На вход макрос получает пару обрабатываемых векторов, а также параметры перестановки элементов и слияния результирующей пары.
Пара макросов объясняется тем, что интринсик swizzle предназначен для перестановки элементов внутри 128-битных четвертей, а permute4f128 переставляет местами эти четверти (обе функции раскрываются в операцию perm).

\begin{singlespace}
\begin{lstlisting}[caption={Определение макросов для реализации фаз суммирования элементов векторов.}, label={lst:text_4_small_matr_swiz_macro}]
#define SWIZ_2_ADD_2_BLEND_1(X, Y, SWIZ_TYPE, BLEND_MASK)\
    _mm512_mask_blend_ps(BLEND_MASK,\
        _mm512_add_ps(X, _mm512_swizzle_ps(X, SWIZ_TYPE)),\
        _mm512_add_ps(Y, _mm512_swizzle_ps(Y, SWIZ_TYPE)))

#define PERM_2_ADD_2_BLEND_1(X, Y, PERM_TYPE, BLEND_MASK)\
    _mm512_mask_blend_ps(BLEND_MASK,\
        _mm512_add_ps(X, _mm512_permute4f128_ps(X, PERM_TYPE)),\
        _mm512_add_ps(Y, _mm512_permute4f128_ps(Y, PERM_TYPE)))
\end{lstlisting}
\end{singlespace}

Последний рассматриваемый в разделе пример -- нахождение обратной матрицы с помощью алгоритма Гаусса-Жордана \texttt{invmat8\_orig}.
По алгоритму Гаусса-Жордана к исходной матрице $m$ нужно приписать справа единичную матрицу $e$.
Получим прямоугольную матрицу вида ($m|e$), размера $8 \times 16$.
Далее над этой матрицей необходимо выполнить такие преобразования строк (перестановка строк, умножение строки на число, прибавление одной строки к другой), чтобы исходная матрица, стоящая слева, трансформировалась в единичную.
Тогда матрица, стоящая справа, из единичной трансформируется в искомую обратную матрицу.
Действия выполняются над строками матрицы размера $8 \times 16$, последовательно хранящейся в памяти.
Так как на вход функции подается матрица $8 \times 8$, также хранящаяся в памяти последовательно, то внутри функции возникают накладные действия, связанные с копированием элементов входной матрицы во временную матрицу $8 \times 16$ и обратным копированием из временной матрицы результата.
Также требуется инициализация правой части временной матрицы элементами единичной матрицы.
Все эти накладные действия реализуются с помощью операций gather/scatter.
Заметим, что при реализации \texttt{invmat16} накладные расходы отсутствуют.

\subsubsection{Векторизация операций с малоразмерными \mbox{матрицами}}\label{sec:text_4_small_matr_realization}

В реализации функции \texttt{matvec8\_opt} (листинг~\ref{lst:text4_small_matr_matvec_opt}) отметим загрузку двух копий вектора в zmm регистр с помощью операции gather.
Существует возможность загрузки двух копий 256-битного участка памяти в zmm регистр с помощью функции-интринсика \texttt{\_mm512\_extload\_pd} с параметром \texttt{\_MM\_BROADCAST\_4X8}, но так как формально результатом является регистр типа \texttt{\_\_m512d}, то было оставлено чтение через gather.
Суммирование половинок четырех zmm регистров заканчивается на операции add третьей фазы, как показано на рис.~\ref{fig:text_4_small_matr_horizontal_add}.

\begin{singlespace}
\begin{lstlisting}[caption={Векторизованная версия умножения матрицы \\ размера $8 \times 8$ на вектор.}, label={lst:text4_small_matr_matvec_opt}]
void matvec8_opt(float* __restrict m, float* __restrict v,
                 float* __restrict r)
{
  ...
  ind_gth = _mm512_set_epi32(7,6,5,4,3,2,1,0,7,6,5,4,3,2,1,0);
  ind_sct = _mm512_set_epi32(0,0,0,0,7,5,3,1,0,0,0,0,6,4,2,0);
  ...
  vec = _mm512_i32gather_ps(ind_gth, v, _MM_SCALE_4);
  ...
  m0 = _mm512_mul_ps(_mm512_load_ps(&m[0]), vec);
  ...
  x0 = SWIZ_2_ADD_2_BLEND_1(m0, m2, _MM_SWIZ_REG_CDAB, 0xAAAA);
  x2 = SWIZ_2_ADD_2_BLEND_1(m4, m6, _MM_SWIZ_REG_CDAB, 0xAAAA);
  m0 = SWIZ_2_ADD_2_BLEND_1(x0, x2, _MM_SWIZ_REG_BADC, 0xCCCC);
  x0 = _mm512_add_ps(m0, _mm512_permute4f128_ps(m0, _MM_PERM_CDAB));
  ...
  _mm512_mask_i32scatter_ps(r, 0xF0F, ind_sct, x0, _MM_SCALE_4);
}
\end{lstlisting}
\end{singlespace}

Перемножение матриц векторизуется аналогично, суммирование половинок регистров заканчивается на операции blend третьей фазы из рис.~\ref{fig:text_4_small_matr_horizontal_add}.

%\begin{singlespace}
%\begin{lstlisting}[caption={Векторизованная версия перемножения \ \\ матриц размера $8 \times 8$.}, label={lst:text_4_small_matr_matmat_opt}]
%void matmat8_opt(float* __restrict a,
%                 float* __restrict b,
%                 float* __restrict r)
%{
% ...
% ind = _mm512_set_epi32(7*V8+1, 6*V8+1, 5*V8+1, 4*V8+1,
%                        3*V8+1, 2*V8+1,   V8+1,      1,
%                        7*V8,   6*V8,   5*V8,   4*V8,
%                        3*V8,   2*V8,     V8,        0);
%
% for (int j = 0; j < V8; j += 2)
% {
%  ...
%  bj = _mm512_i32gather_ps(ind, &b[j], _MM_SCALE_4);
%  bj2 = _mm512_permute4f128_ps(bj, _MM_PERM_BADC);
%  ...
%  a0 = _mm512_load_ps(&a[ii0]);
%  m0 = _mm512_mul_ps(a0, bj);
%  m1 = _mm512_mul_ps(a0, bj2);
%  ...
%  x0 = SWIZ_2_ADD_2_BLEND_1(m0, m1, _MM_SWIZ_REG_CDAB, 0xAAAA);
%  x1 = SWIZ_2_ADD_2_BLEND_1(m2, m3, _MM_SWIZ_REG_CDAB, 0xAAAA);
%  x2 = SWIZ_2_ADD_2_BLEND_1(m4, m5, _MM_SWIZ_REG_CDAB, 0xAAAA);
%  x3 = SWIZ_2_ADD_2_BLEND_1(m6, m7, _MM_SWIZ_REG_CDAB, 0xAAAA);
%  m0 = SWIZ_2_ADD_2_BLEND_1(x0, x1, _MM_SWIZ_REG_BADC, 0xCCCC);
%  m1 = SWIZ_2_ADD_2_BLEND_1(x2, x3, _MM_SWIZ_REG_BADC, 0xCCCC);
%  x0 = PERM_2_ADD_2_BLEND_1(m0, m1, _MM_PERM_CDAB, 0xF0F0);
%  ...
%  ind1 = _mm512_set_epi32(ii3+V8+j, ii3+V8+j+1,
%                          ii2+V8+j, ii2+V8+j+1,
%                          ii1+V8+j, ii1+V8+j+1,
%                          ii0+V8+j, ii0+V8+j+1,
%                          ii3+j+1,  ii3+j,
%                          ii2+j+1,  ii2+j,
%                          ii1+j+1,  ii1+j,
%                          ii0+j+1,  ii0+j),
%  _mm512_i32scatter_ps(r, ind1, x0, _MM_SCALE_4);
%}
%\end{lstlisting}
%\end{singlespace}

Реализация \texttt{invmat8\_opt} начинается с формирования временной матрицы размера $8 \times 16$, после ее инициализации выполняется тело алгоритма Гаусса-Жордана.
Действие по нахождению ведущей строки не подвергалось векторизации.
Три остальные действия реализуются без каких бы то ни было особенностей с помощью применения пересылок и покомпонентных операций сложения, умножения и комбинированных FMA\label{abbr:fma-2} операций (листинг~\ref{lst:vec_invmat8_opt}).

\begin{singlespace}
\begin{lstlisting}[caption={Векторизованная версия вычисления обратной \\ матрицы размера $8 \times 8$.},label={lst:text_4_small_matr_invmat_opt}, label={lst:vec_invmat8_opt}]
int invmat8_opt(float* __restrict m, float* __restrict r)
{
  z0 = _mm512_setzero_ps();
  z1 = _mm512_set1_ps(1.0);
  ind1 = _mm512_set_epi32(V16+7,V16+6,V16+5,V16+4,V16+3,V16+2,V16+1,V16,
                          7,6,5,4,3,2,1,0);
  ind2 = _mm512_set_epi32(0,0,0,0,0,0,0,0,
                          7*V16+7,6*V16+6,5*V16+5,4*V16+4,
                          3*V16+3,2*V16+2,V16+1,0);

  for (int i = 0; i < V8; i += 2)
  {
    _mm512_i32scatter_ps(&t[i * V16], ind1, _mm512_load_ps(&m[i * V8]),
                         _MM_SCALE_4);
    _mm512_i32scatter_ps(&t[i * V16 + V8], ind1, z0, _MM_SCALE_4);
  }

  _mm512_mask_i32scatter_ps(&t[V8], 0xFF, ind2, z1, _MM_SCALE_4);

  for (int i = 0; i < V8; ++i)
  {
    ...
    if (lead_i != i)
    {
      vi = _mm512_load_ps(&t[ii]);
      vl = _mm512_load_ps(&t[lead_i * V16]);
      _mm512_store_ps(&t[lead_i * V16], vi);
      _mm512_store_ps(&t[ii], vl);
    }
    ...
    vd = _mm512_set1_ps(1.0 / t[ii + i]);
    vi = _mm512_load_ps(&t[ii]);
    vi = _mm512_mul_ps(vi, vd);
    _mm512_store_ps(&t[ii], vi);
    ...
    for (int j = 0; j < V8; ++j)
    {
      int jj = j * V16;
      if (j != i)
      {
        vd = _mm512_set1_ps(-t[jj + i]);
        vj = _mm512_load_ps(&t[jj]);
        vi = _mm512_load_ps(&t[ii]);
        vj = _mm512_fmadd_ps(vi, vd, vj);
        _mm512_store_ps(&t[jj], vj);
      }
    }
  }

  ...
  for (int i = 0; i < V8; i += 2)
  {
    vi = _mm512_i32gather_ps(ind, &t[i * V16 + V8], _MM_SCALE_4);
    _mm512_store_ps(&r[i * V8], vi);
  }
}
\end{lstlisting}
\end{singlespace}

Реализация функций по работе с матрицами $16 \times 16$ выполняется аналогично.
Выполнение горизонтальных операций сложения для \texttt{matvec16} и \texttt{matmat16} охватывает все четыре фазы из рис.~\ref{fig:text_4_small_matr_horizontal_add}.
Полные тексты приведенного в разделе программного кода доступны в \cite{iparGithub}.

Реализованные оптимизированные с помощью инструкций AVX-512 функции для работы с матрицами размера $8 \times 8$ и $16 \times 16$ были опробованы на процессоре Intel Xeon Phi KNL\label{abbr:knl-6}.
Рассматривались два варианта исполняемого кода.
В первом варианте функции были реализованы без использования интринсиков, компилировались с использованием компилятора icc с уровнем оптимизации -O3.
Во втором варианте использовались те же опции компиляции, однако функции были оптимизированы вручную, согласно описанию в этом разделе.
На рис.~\ref{fig:text_4_small_matr_res} приведены данные по ускорению векторных версий функций работы с матрицами.

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./fig/vec_small_matr_res.png}
\singlespacing
\captionstyle{center}\caption{Ускорение и эффективность векторизации операций над матрицами размера $8 \times 8$ и $16 \times 16$.}
\label{fig:text_4_small_matr_res}
\end{figure}

Наибольшее ускорение продемонстрировали функции нахождения обратной матрицы, так как алгоритм нахождения обратной матрицы естественным образом формулируется в терминах работы со строками объединенной матрицы, что находит свое отражение в 512-битных векторных операциях.
Функция \texttt{invmat16} ускорилась больше, чем \texttt{invmat8} из-за отсутствия накладных расходов.
Функции \texttt{matvec8/16} и \texttt{matmat8/16} демонстрируют умеренное ускорение из-за наличия горизонтальных операций сложения.
Объединение горизонтальных операций позволяет сгладить этот эффект, однако для дальнейшего ускорения требуется реализация объединенных функций, выполняющих одновременно сразу несколько операций или применяющих одну операцию к более широкому набору данных (например, функция перемножение двух пар матриц).

% Векторизация перемножения матриц специального вида.
\subsubsection{Потери производительности из-за неполного \mbox{использования} элементов векторных регистров}\label{sec:text_4_spec_matr}

В разделах~\ref{sec:vec_small_matr_opers} и \ref{sec:text_4_small_matr_realization} рассматривались матрицы размера $8 \times 8$ и $16 \times 16$, работа с которыми удобна в плане векторизации, так как в один векторных регистр помещается ровно 8 значений формата double или 16 значений формата float.
Однако, при работе с другими размерностями неизбежно возникает проблема неполного использования элементов векторных регистров, что приводит к падению производительности.

При проведении вычислений с помощью метода RANS/ILES\label{abbr:rans-3}\label{abbr:iles-3} расчетные параметры компонуются внутри матриц размером $5 \times 5$, эти матрицы являются подматрицами матриц размера $8 \times 8$ (это делается из соображений выровненности расположения в памяти).
Будем рассматривать операцию перемножения таких матриц и возможные пути повышения производительности этой операции \cite{Bendersky2018VecMat1}. 

\begin{figure}[ht]
\centering
\includegraphics[width=1.00\textwidth]{./fig/vec_spec_matrices.pdf}
\singlespacing
\captionstyle{center}\caption{Иллюстрация матриц размера $8 \times 8$, $7 \times 7$, $6 \times 6$, $5 \times 5$, представленных как подматрицы матрицы $8 \times 8$.}
\label{fig:text_4_spec_matr_matrices}
\end{figure}

Идея выделения однотипных операций из раздела~\ref{sec:text_4_small_matr_realization} обладает существенными недостатками.
Во-первых, в коде присутствуют медленные инструкции gather/scatter.
Во-вторых, выполнение сначала поэлементного перемножения векторов, а затем параллельное нахождение сумм их элементов (в рассматриваемом случае рассчитываются суммы элементов половинок векторов) делают невозможным использование комбинированных инструкций fmadd.

Запишем значения элементов $i$-й строки результирующей матрицы:
\begin{equation}
	\left\{
		\begin{aligned}
			& r_{i0} = a_{i0}b_{00} + a_{i1}b_{10} + \cdots + a_{i7}b_{70} \\
			& \cdots \\
			& r_{i7} = a_{i0}b_{07} + a_{i1}b_{17} + \cdots + a_{i7}b_{77}
		\end{aligned}
	\right.
\end{equation}
или в векторном виде $\overline{r}_i = a_{i0}\overline{b}_0 + a_{i1}\overline{b}_1 + \cdots + a_{i7}\overline{b}_7$, что в объединении с выражением для $i + 1$-ой строки $\overline{r}_{i + 1} = a_{i + 1,0}\overline{b}_0 + a_{i + 1,1}\overline{b}_1 + \cdots + a_{i + 1,7}\overline{b}_7$ приводит к выражению
\begin{equation}\label{eqn:text_4_spec_matr_riip1}
	\overline{r}|_{i + 1}^i
	=
	\sum_{j = 0}^{7} \left(  \overline{a}|_{i + 1,j}^{ij} \circ \overline{b}|_j^j \right),
\end{equation}
где $\overline{r}|_{i + 1}^i$ -- комбинированный вектор состоящий из векторов $\overline{r}_i$ и $\overline{r}_{i + 1}$, $\overline{b}|_j^j$ -- комбинированный вектор состоящий из двух копий вектора $\overline{b}_j$, а $\overline{a}|_{i + 1,j}^{ij}$ -- вектор, первые 8 элементов которого равны $a_{ij}$, а остальные 8 элементов равны $a_{i + 1,j}$.
Получающийся по формуле~\eqref{eqn:text_4_spec_matr_riip1} комбинированный вектор $\overline{r}|_{i + 1}^i$ расположен в памяти последовательно, и записывать его в память можно с помощью интринсика \texttt{\_mm512\_store\_ps}.
При этом предполагаем, что значение $i$ четно, то есть вектор $\overline{r}|_{i + 1}^i$ выровнен в памяти должным образом.
Другие комбинированные векторы в \eqref{eqn:text_4_spec_matr_riip1} получаются с помощью инструкции perm (интринсик \texttt{\_mm512\_permutexvar\_ps}), примененной к соответствующим загруженным соседним строкам матриц $a$ и $b$.
При реализации \eqref{eqn:text_4_spec_matr_riip1} не требуется использование медленных инструкций gather/scatter, так как столбцы матриц не читаются и не записываются (работа ведется только со строками).
После того, как векторы $\overline{a}|_{i + 1,j}^{ij}$ и $\overline{b}|_j^j$ сформированы, нужно выполнить их попарное поэлементное перемножение, после чего сложить в один вектор (8 операций поэлементного умножения, 7 операций сложения).
Эти действия можно выполнить, используя комбинированные операции fmadd.
Для вычисления значения $\overline{r}|_{i + 1}^i$ потребуется 8 векторных операций (1 mul и 7 fmadd) (см. рис.~\ref{fig:text_4_spec_matr_fmadd}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.00\textwidth]{./fig/vec_spec_matrices_fmadd.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычисления двух соседних строк результирующей матрицы путем последовательного сложения попарно перемноженных векторов.}
\label{fig:text_4_spec_matr_fmadd}
\end{figure}

%\begin{lstlisting}[caption={Векторизованная версия перемножения матриц $8 \times 8$.},label={lst:text_4_spec_matr_mul8x8_opt}]
%void mul_8x8_opt(float* __restrict a, float* __b, float* __restrict r)
%{
%    ...
%    ind_df = _mm512_set_epi32(7,6,5,4,3,2,1,0,7,6,5,4,3,2,1,0);
%    ind_ds = _mm512_set_epi32(15,14,13,12,11,10,9,8,
%                              15,14,13,12,11,10,9,8);
%    ...
%    b0 = LD(&b[0]);
%    b1 = _mm512_permutexvar_ps(ind_ds, b0);
%    b0 = _mm512_permutexvar_ps(ind_df, b0);
%    ...
%    b6 = LD(&b[6 * V8]);
%    b7 = _mm512_permutexvar_ps(ind_ds, b6);
%    b6 = _mm512_permutexvar_ps(ind_df, b6);
%
%    a0 = LD(&a[0]);
%    ...
%    a6 = LD(&a[6 * V8]);
%
%    ind_0 = _mm512_set_epi32(8,8,8,8,8,8,8,8,0,0,0,0,0,0,0,0);
%    ...
%    ind_7 = _mm512_set_epi32(15,15,15,15,15,15,15,15,
%                             7,7,7,7,7,7,7,7);
%
%#define BLOCK(N, A)                           \
%    ST(&r[N * V8],                            \
%      FMADD(PERMXV(ind_0, A), b0,             \
%        FMADD(PERMXV(ind_1, A), b1,           \
%          FMADD(PERMXV(ind_2, A), b2,         \
%            FMADD(PERMXV(ind_3, A), b3,       \
%              FMADD(PERMXV(ind_4, A), b4,     \
%                FMADD(PERMXV(ind_5, A), b5,   \
%                  FMADD(PERMXV(ind_6, A), b6, \
%                    MUL(PERMXV(ind_7, A), b7)))))))));
%
%    BLOCK(0, a0);
%    BLOCK(2, a2);
%    BLOCK(4, a4);
%    BLOCK(6, a6);
%}
%\end{lstlisting}

Рассмотрим перемножения двух матриц размера $8 \times 8$, с помощью использования комбинированных операций.
Для реализации выполним полную загрузку обеих матриц $a$ и $b$.
Далее требуется сформировать 8 векторов вида $\overline{b}|_j^j$, для чего потребуется еще 8 операций perm (для каждой пары загруженных строк матрицы $b$ нужно выполнить дублирование первой строки и дублирование второй строки).
После подготовки всех необходимых данных выполняется вычисление значений результирующей матрицы.
Схема с рис.~\ref{fig:text_4_spec_matr_fmadd} представляет собой блок операций, обеспечивающий вычисление двух соседних строк результирующей матрицы.
Реализация блока состоит из 8 операций perm, 1 операции mul и 7 операций fmadd, кроме того выполняется одна операция записи в память.
Всего выполняется четыре таких блока, что в сумме и с учетом операций подготовки данных приводит к следующему итогу: 8 простых операций чтения из памяти, 40 операций perm, 4 операции mul, 28 операций fmadd, 4 простые операции записи в память.
Итоговый код доступен в \cite{iparGithub}.

Заметим, что 28 векторных операций fmadd и 4 векторные операции mul соответствуют $(28 \times 2 + 4) \times 16 = 960$ скалярным операциям, что в точности совпадает с количеством скалярных операций, требуемых для выполнения перемножения двух матриц размера $8 \times 8$.
Таким образом, в реализации нет лишних арифметических операций.

При реализации перемножения матриц размера $7 \times 7$, $6 \times 6$, $5 \times 5$ удаляются заведомо лишние векторные операции (например, умножение на вектор, все элементы которого равны нулю), однако все равно остаются элементы векторов, обработка которых избыточна, что приводит к снижению эффективности векторизации в этих случаях.
Приведем таблицу с точным подсчетом количества скалярных операций для невекторизованных функций и количества векторных операций для их векторизованных аналогов (см. таблицу~\ref{tbl:text_4_spec_matr_tabl}).

\begin{table}
\centering
\singlespacing
\captionstyle{center}\caption{Статистика по количеству операций в невекторизованном и векторизованном вариантах функций перемножения матриц размера $8 \times 8$, $7 \times 7$, $6 \times 6$, $5 \times 5$.}
\bigskip
\label{tbl:text_4_spec_matr_tabl}
\begin{tabular}{ | c | c | c | }
  \hline
  \ & Невекторизованный вариант & Векторизованный вариант \\ \hline\hline
  $8 \times 8$ & \makecell{512 mul, 448 add \\ 960 арифметических операций} & \makecell{4 mul, 28 fmadd, 40 perm \\ 960 арифметических операций} \\ \hline
  $7 \times 7$ & \makecell{343 mul, 294 add \\ 637 арифметических операций} & \makecell{4 mul, 24 fmadd, 35 perm \\ 832 арифметические операции} \\ \hline
  $6 \times 6$ & \makecell{216 mul, 180 add \\ 396 арифметических операций} & \makecell{3 mul, 15 fmadd, 24 perm \\ 528 арифметических операций} \\ \hline
  $5 \times 5$ & \makecell{125 mul, 100 add \\ 225 арифметических операций} & \makecell{3 mul, 12 fmadd, 20 perm \\ 432 арифметические операции}
 \\ \hline
\end{tabular}
\end{table}

Из таблицы~\ref{tbl:text_4_spec_matr_tabl} видно, что с уменьшением размера перемножаемых матриц возрастает избыточность вычислений (для размера $5 \times 5$ эта избыточность почти достигает двукратного размера), что сказывается отрицательно на эффективности векторизации.

\begin{figure}[ht]
\centering
\includegraphics[width=1.00\textwidth]{./fig/vec_spec_matrices_stat.png}
\singlespacing
\captionstyle{center}\caption{Количество операций в скалярных и векторных вариантах перемножения матриц разных размеров.}
\label{fig:text_4_spec_matr_stat}
\end{figure}

На рис.~\ref{fig:text_4_spec_matr_stat} приведена статистика по количеству операций mul и add в скалярных версиях перемножения матриц, а также mul, fmadd и perm в векторизованных версиях.

Приведенный способ векторизации перемножения матриц размера был опробован на процессоре Intel Xeon Phi KNL.
Были рассмотрены 4 функции: \texttt{mul\_8x8}, \texttt{mul\_7x7}, \texttt{mul\_6x6}, \texttt{mul\_5x5}, выполняющие перемножение матриц соответствующих размеров.
Для каждой функции были рассмотрены 3 варианта реализации.
В качестве первого варианта был использован способ векторизации с параллельным вычислением сумм элементов векторов из раздела~\ref{sec:text_4_small_matr_realization} (обозначен \texttt{VECT\_OLD}).
Для этого метода была применена оптимизация для сокращения количества операций по обращению в память.
В качестве второго варианта было взято прямое ручное вычисление каждого элемента результирующей матрицы, в котором все циклы были удалены и для каждого элемента путем многократного копирования был написан скалярный код (обозначен \texttt{FULL\_UNROLL}), в качестве третьего варианта взят рассмотренный подход, основанный на обращениях только к строкам матриц и использовании комбинированных операций fmadd (обозначен \texttt{VECT\_NEW}).

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./fig/vec_spec_matrices_res.png}
\singlespacing
\captionstyle{center}\caption{Ускорение и эффективность векторизации перемножения матриц с помощью подходов \texttt{OLD\_VECT}, \texttt{FULL\_UNROLL}, \texttt{NEW\_VECT}.}
\label{fig:text_4_spec_matr_res}
\end{figure}

На рис.~\ref{fig:text_4_spec_matr_res} показаны результаты тестирования рассмотренных подходов на машине.
Из рисунка следует, что \texttt{OLD\_VECT} оказался наименее эффективным подходом, его применение даже менее выгодно, чем прямое написание скалярного кода.
Для матриц размера $5 \times 5$ этот метод оптимизации вовсе приводит к замедлению оригинальной неоптимизированной версии функции.
Метод \texttt{NEW\_VECT} демонстрирует наилучший результат, на матрицах размера $8 \times 8$ продемонстрировано ускорение почти в 6 раз по сравнению с оригинальным кодом.
При понижении размерности матриц эффективность векторизации несколько снижается, однако даже для матриц размера $5 \times 5$ наблюдается ускорение примерно в 2,5 раза.

%---------------------------------------------------------------------------------------------------
% 5.3 - плоский цикл

% Плоский цикл.
\subsection{Плоский цикл}\label{sec:text_4_flat}

В разделе~\ref{sec:text_4_small_matr} были рассмотрены различные варианты векторизации функций, реализующих работу с малоразмерными матрицами и матрицами специального вида.
Эти варианты базировались на идее выделения однотипных операций замены их на векторные аналоги.
Из результатов в разделе~\ref{sec:text_4_small_matr} можно заключить, что эффективность векторизации сильно зависит от способа выделения таких однотипных операций, от порядка обращения в память за данными, от избыточности вычислений и других факторов.

Неоднозначность и искусственность векторизации программного кода путем поиска однотипных операций порождает потребность выработки некоторого универсального подхода к векторизации, который мог бы применяться к широкому спектру расчетных приложений.
Выполним поиск такого программного контекста, векторизация которого может быть выполнена достаточно прозрачно, а результирующий код будет обладать высокой степенью эффективности.

\subsubsection{Понятие плоского цикла}

Векторизация программного контекста не может быть применена автоматически к коду произвольного вида.
В этом разделе определим подходящий для векторизации программный контекст специального вида -- плоский цикл -- и опишем его свойства \cite{Shabanov2021VecCFG}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{./fig/vec_block_BLOCK.pdf}
\singlespacing
\captionstyle{center}\caption{Скалярный блок block и аналогичный ему \\ векторный блок BLOCK.}
\label{fig:text_4_vec_flat_fun_FUN}
\end{figure}

Идея плоского цикла состоит в объединении $w$ экземпляров скалярного блока в единый векторный блок, состоящий из аналогичных векторных инструкций.
На рис.~\ref{fig:text_4_vec_flat_fun_FUN} слева представлена схема скалярного блока \texttt{block}, со скалярными входными данными $x$ и $y$ и скалярным результатом $r$.
Будем считать, что этот блок соответствует концепции чистых вычислений, то есть результат его выполнения зависит только от значений $x$ и $y$ (например, отсутствуют побочные эффекты через глобальную память или операции ввода-вывода).
Идеология чистых вычислений берет свое начало из парадигмы функционального программирования \cite{Armstrong2013VecErlang}, использование такого подхода открывает возможности для оптимизации программного кода, в частности для компиляторов.
Если рассмотреть вместо одной копии скалярного блока \texttt{block} несколько копий ($w$ штук) с разными наборами входных данных, то их можно трактовать как выполнение векторного блока \texttt{BLOCK}, входными данными которого являются векторы $X$ и $Y$ длины $w$, а выходным значением является вектор $R$ также длины $w$.
В этом случае можно говорить, что векторный блок \texttt{BLOCK} представляет собой векторизованную версию скалярного блока \texttt{block} при ширине векторизации $w$ (рис.~\ref{fig:text_4_vec_flat_fun_FUN} справа).
В этом случае логику векторного блока \texttt{BLOCK} можно записать в виде, представленном на листинге~\ref{lst:text_4_vec_flat_FUN_sem}.

\begin{singlespace}
\begin{lstlisting}[caption={Логика векторного блока \texttt{BLOCK}.},label={lst:text_4_vec_flat_FUN_sem}]
// BLOCK
for (int i = 0; i < w; ++i)
{
   	r[i] = block(x[i], y[i])
}
\end{lstlisting}
\end{singlespace}

Цикл вида, представленного на в листинге~\ref{lst:text_4_vec_flat_FUN_sem}, будем называть плоским циклом.
Определим свойства, присущие плоскому циклу.

В качестве плоского цикла будем рассматривать цикл for с индуктивной переменной $i \in [0, w - 1]$ (\texttt{for (int i = 0; i < w; ++i}).
Такое условие не является строгим ограничением, так как произвольный цикл for с количеством итераций $n$ может быть разбит (с помощью расщепления по индуктивной переменной) на $\left\lfloor \frac{n}{w} \right\rfloor$ циклов с количеством итераций $w$ каждый, а также одного цикла с количеством итераций $n - \left\lfloor \frac{n}{w} \right\rfloor w$ (если $w \nmid n$), называемого эпилогом цикла.
Будем считать, что мы рассматриваем циклы с большим числом итераций $n \gg 1$.
В таком случае эпилогом цикла можно пренебречь, поэтому будем считать, что $w \mid n$, и эпилог отсутствует.

Во-вторых, будем считать, что внутри плоского цикла на $i$-ой итерации все обращения в память на запись имеют вид \texttt{a[i]}.
Обращения к глобальным данным на чтение могут иметь вид \texttt{a[i]} либо могут быть обращениями к глобальным скалярным данным.
Такое ограничение гарантирует отсутствие конфликтов между итерациями по обращениям в память.
Дополнительно будем считать, что при обращении в память все данные выровнены правильным образом, то есть адрес элемента \texttt{a[0]} выровнен в памяти на размер вектора.

Последним требованием будем считать отсутствие других межитерационных зависимостей внутри цикла.
Пример цикла с межитерационными зависимостями (обращение к глобальной переменной $s$), можно увидеть на листинге~\ref{lst:text_4_vec_not_flat}.

\begin{lstlisting}[caption={Пример цикла с межитерационной зависимостью.},label={lst:text_4_vec_not_flat}]
for (int i = 0; i < w; ++i)
{
   	s += x[i];
}
\end{lstlisting}

\begin{definition}
Плоским циклом будем называть цикл for, в котором индуктивная переменная $i$ последовательно принимает значения от $0$, до $w - 1$, где $w$ -- ширина векторизации (\texttt{for (int i = 0; i < w; ++i)}), и удовлетворяющий требованиям по обращению к глобальным данным (на $i$-ой итерации все обращения к данным на запись имеют вид \texttt{a[i]}, а обращения к данным на чтение имеют вид либо \texttt{a[i]}, либо являются чтением скаляров), выравниванию глобальных данных в памяти (все массивы данных, обращение к которым на $i$-ой итерации имеет вид \texttt{a[i]}, выровнены в памяти на размер вектора), а также отсутствию других межитерационных зависимостей.
\end{definition}

\begin{definition}
Цикл \texttt{for (int i = 0; i < w; ++i)}, в котором нарушаются некоторые требования, предъявляемые к плоским циклам, будем называеть квазиплоским.
\end{definition}

Учитывая все требования, предъявляемые к плоскому циклу, можно заключить, что итерации плоского цикла являются независимыми, а значит могут выполняться в произвольном порядке, в том числе и одновременно.

Плоские циклы, обладающие этими свойствами, представляют собой удобный контекст для векторизации, и в большинстве случаев они могут быть векторизованы с помощью векторных инструкций AVX-512\label{abbr:avx-8} с помощью перевода тела цикла в предикатное представление и замены скалярных инструкций векторными аналогами, реализованными с помощью функций-интринсиков \cite{IntelIntrinsicsGuide,Savin2020VecFlat}.
Таким образом, плоский цикл зачастую может быть заменем на векторный блок (или на несколько соседних векторных блоков в случае произвольного количества итераций $n > w$).

Многие практические вычислительные задачи состоят из выполнения однотипных вычислений, применяемых к разным наборам данных, которые можно сгруппировать, трансформировав в плоский цикл, как это продемонстрировано на рис.~\ref{fig:text_4_vec_flat_fun_FUN} на примере скалярного блока \texttt{block}.

Сложность векторизации тела полученного плоского цикла зависит от особенностей исходного блока \texttt{block}.
Чем сложнее управление внутри тела векторизуемого плоского цикла, тем больше трудностей может возникнуть в процессе выполнения векторизации.
Граф потока управления цикла используется для оценки анализа возможности векторизации этого цикла.

\subsubsection{Представление структуры тела плоского цикла в виде графа потока управления}

Граф потока управления (control flow graph, CFG)\label{abbr:cfg-1} является одним из видов промежуточного представления программы, которые используются в частности для выполнения оптимизаций исполняемого кода \cite{Muchnick1997Compilers}.
Узлами этого графа являются линейные участки, состоящие из последовательностей инструкций, а ребрами -- передача управления между этими линейными участками \cite{Rybakov2013CGF}.
Граф потока управления является логической структурой, отражающей параллелизм программы на уровне линейных участков.
Он активно используется компилятором для применения различных глобальных оптимизаций \cite{Aho2006Compilers}.

Кроме самой структуры графа потока управления для оптимизации программного кода важна статистическая информация об исполнении программы: количество выполнений различных линейных участков и данные о частоте переходов между ними.
Такая статистическая информация называется профилем исполнения, и для корректного проведения оптимизаций требуется правильным образом собирать и корректировать этот профиль \cite{Chetverina2015Profile}.
Для векторизации программного кода профиль исполнения программы приобретает особенную важность, так как на эффективность векторизации сильно влияет плотность и даже структура векторных масок, которая сильно разнится при сравнении результатов, полученных при генерации случайных входных данных, и при использовании данных реальных расчетов.

\begin{definition}
Плотностью векторной маски будем называть отношение количества единичных битов в ней к ее длине.
\end{definition}

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{./fig/vec_cfg.pdf}
\singlespacing
\captionstyle{center}\caption{Узел CFG с входящими и выходящими ребрами.}
\label{fig:text_4_vec_flat_cfg}
\end{figure}

В качестве профиля исполнения приложения будем использовать данные, содержащие только счетчики узлов и ребер, а также вероятности ребер.
Обозначим некоторый узел CFG через $v$.
Пусть в него входят несколько ребер, а также выходят несколько ребер (рис.~\ref{fig:text_4_vec_flat_cfg}).

\begin{definition}
Счетчиком ребра $e$ будем называть количество переходов по этому ребру в процессе выполнения программы.
Значение счетчика ребра будем обозначать $n(e)$.
\end{definition}

\begin{definition}
Счетчиком узла $v$ будем называть суммарное количество счетчиков всех входных ребер либо всех выходных ребер.
%\begin{equation}
%	n(v) = \sum_{e \in E_i(v)}{n(e)} = \sum_{e \in E_o(v)}{n(e)}
%\end{equation}
\end{definition}

\begin{definition}
Вероятностью ребра $e$ будем называть отношение счетчика этого ребра с счетчику узла, из которого это ребро выходит.
\begin{equation}
	\forall e \in E_o(v): p(e) = \frac{n(e)}{n(v)}
\end{equation}
\end{definition}

Построенный по телу плоского цикла граф потока управления с собранным профилем исполнения используется для принятия решения о выборе методов векторизации программного контекста.

\subsubsection{Семантика векторных инструкций AVX-512 с точки зрения плоского цикла}

Векторные инструкции AVX-512\label{abbr:avx-9} позволяют не просто объединять $w$ однотипных скалярнях операций, но также обеспечивают выборочное их исполнение с помощью векторных масок (предикатов), что делает инструкции AVX-512 мощным инструментом для векторизации плоских циклов.
В этом разделе опишем семантику некоторых векторных инструкций AVX-512, пригодных для векторизации плоских циклов.
При этом основное внимание будем уделять операциям, работающим с вещественными числами, так как обычно они являются основой высоконагруженных суперкомпьютерных приложений.
Все приводимые ниже векторные инструкции работают с упакованными данными формата float, для данных формата double в AVX-512 существуют аналогичные инструкции.

Условимся обозначать маленькими латинскими буквами элементы данных, с которыми мы оперируем в процессе счета (в рассматриваемом случае это вещественные элементы данных формата float).
Арифметические операции будем записывать в естественном виде, например $r = a + b$ означает вычисление суммы двух элементов данных.
Векторы, составленные из отдельных элементов будем записывать с помощью заглавных латинских букв.
То есть будем считать, что $A$ это вектор, состоящий из $w$ отдельных элементов $A[i]$.
Под записью $R = A + B$ будем понимать поэлементную сумму векторов $A$ и $B$ и копирование результата в вектор $R$.
Заменяя операцию сложения произвольной операцией $op$ (не обязательно операцией двух аргументов), получим запись семантики векторной поэлементной операции в виде $R = op \ A, B$.

Для рассмотрения семантики векторных операций, работающих с масками, нам понадобится представление векторных предикатов.
Предикаты будем обозначать латинскими буквами в галочкой наверху.
Использование предиката при выборе одного из двух аргументов будем записывать с помощью тернарного оператора.
Таким, образом в выражении $r = \check{p} \ ? \ a : b$ элемент $r$ принимает значение $a$ при истинном значении предиката $\check{p}$, в противном случае он принимает значение $b$.
В векторном аналоге этой записи $R = \check{P} \ ? \ A : B$ эта операция выполняется поэлементно для элементов векторов, находящихся в позиции $i$ ($0 \le i < w$).

После рассмотрения записи семантики векторных инструкций для векторизации плоских циклов рассмотрим основные классы пригодных для этого инструкций (примеры операций и их семантика приведены в таблице~\ref{tbl:text_4_flat_avx512semantic}).

\begin{table}
\centering
\singlespacing
\captionstyle{center}\caption{Инструкции AVX-512 для работы с вещественными числами \\ и их семантика.}
\bigskip
\label{tbl:text_4_flat_avx512semantic}
\begin{tabular}{ | c | c | }
  \hline
  Имя инструкции & Семантика инструкции \\ \hline\hline
  \makecell{VMOVAPS, VMOVUPS, VSQRTPS, \\ VGETEXPPS, VGETMANTPS, \\ VRCP14PS, VREDUCEPS, VRNDSCALEPS, \\ VRSQRT14PS, VSCALEFPS} & $\begin{matrix} R = op \ A \\ R = \check{P} \ ? \ (op \ A) : R \\ R = \check{P} \ ? \ (op \ A) : 0 \end{matrix}$ \\ \hline
  \makecell{VADDPS, VANDPS, VANDNPS, VDIVPS, \\ VMAXPS, VMINPS, VMULPS, VORPS, \\ VSUBPS, VRANGEPS} & $\begin{matrix} R = op \ A, B \\ R = \check{P} \ ? \ (op \ A, B) : R \\ R = \check{P} \ ? \ (op \ A, B) : 0 \end{matrix}$ \\ \hline
  \makecell{VFMADD*PS, VFMSUB*PS, \\ VFNMADD*PS, VFNMSUB*PS} & $\begin{matrix} R = op \ R, A, B \\ R = \check{P} \ ? \ (op \ R, A, B) : R \\ R = \check{P} \ ? \ (op \ R, A, B) : 0 \end{matrix}$ \\ \hline
  \makecell{VCMPPS} & $\begin{matrix} \check{P} = op \ A, B \\ \check{P} = \check{Q} \ ? \ (op \ A, B) : 0 \end{matrix}$ \\ \hline
  \makecell{VBLENDPS} & $\begin{matrix} R = \check{P} \ ? \ A : B \end{matrix}$ \\ \hline
\end{tabular}
\end{table}

Первым типом операций являются векторные операции с одним аргументом.
В этом случае к каждому элементу вектора применяется одна и та же операция, после чего результаты записываются в результирующий вектор.
С помощью дополнительного предикатного аргумента можно выбрать множество обрабатываемых элементов вектора.
Если же к элементу вектора не должна быть применена рассматриваемая операция, то соответствующий элемент результирующего вектора может быть либо оставлен без изменения либо обнулен, что регулируется отдельным флагом в инструкции.

Аналогичным образом записывается семантика арифметических векторных инструкций с двумя и тремя аргументами.
Арифметические операции с тремя аргументами это так называемые сдвоенные, или комбинированные FMA\label{abbr:fma-3} операции, которые позволяют за одну операцию вычислитель значение $\pm a \cdot b \pm c$.

Следующий большой класс операций это операции сравнения.
В таблице~\ref{tbl:text_4_flat_avx512semantic} этот класс представлен единственной операцией VCMPPS, однако данная операция скрывает в себе все множество различных операций сравнения (VCMPEQPS, VCMPLEPS, VCMPNEPS и остальные), что регулируется отдельным параметром.
Эти операции выполняют поэлементное сравнение двух векторов и записывают результаты в векторный предикат.

Последний рассматриваемый класс векторных инструкций представлен одной инструкцией VBLENDPS, которая является реализацией векторного тернарного оператора $R = \check{P} \ ? \ A : B$ (эта операция широко используется при оптимизации кода, будем называть ее слиением векторов по маске).

На самом деле, глядя на таблицу~\ref{tbl:text_4_flat_avx512semantic}, можно заметить, что описания семантики всех приведенных в ней векторных операций являются просто плоскими циклами в явном виде.
Верно также и обратное -- если некий плоский цикл можно записать в виде семантики одной или нескольких векторных инструкций, то он может быть реализован с помощью этих инструкций.

% Векторизация метода погруженных границ - потери производительности при векторизаии неплоских циклов.
\subsubsection{Векторизация с помощью представления расчетов в виде композиции плоских циклов}\label{sec:text_4_ibm}

Если вычисления организованы таким образом, что они могут трактоваться как композиция плоских циклов, а тела этих плоских циклов являются достаточно простыми с точки зрения управления, оптимизирующий компилятор может успешно создавать векторный код.
В этом случае даже нет необходимости явно использовать ассемблерные вставки или функции-интринсики.
В этом разделе рассмотрим основные аспекты приведения программного кода в форму, пригодную для автоматической векторизации \cite{Rybakov2023VecIBM}.
Подходы, применяемые к векторизации плоских циклов, могут частично применяться также к квазиплоским циклам.
Такие циклы все равно могут быть векторизованы, однако это может приводить к потере производительности.
В этом разделе проведен анализ потерь производительности при векторизации квазиплоских циклов на примере газодинамических расчетов с использованием метода погруженных границ, реализация которого приведена в разделе~\ref{sec:text_1_immersed_boundary_method_realization}.

Для анализа эффективности векторизации проводился эксперимент по организации программного кода газодинамического решателя, работающего с данными в формате fp64 с целью векторизации под микропроцессоры Intel Xeon Phi KNL\label{abbr:knl-7}.
Тексты программных кодов доступны в \cite{ibmGithub}.

Рассмотрим на примере реализации функции \texttt{d\_to\_u} из общей схемы вычислений, представленной на рис.~\ref{fig:text_4_ibm_immersed_boundary_method_cheme}, способы организации данных для эффективного проведения вычислений.
Итак, функция \texttt{d\_to\_u} переводит вектор величин $D = [\rho, u, v, w, p]$ в вектор величин $U = [\rho, \rho u, \rho v, \rho w, E]$ для каждой расчетной ячейки.
При этом все ячейки обрабатываются в цикле независимо друг от друга.
Интуитивным способом вычисления могут быть организованы в виде следующей схемы: для каждой ячейки создается структура, которая содержит все необходимые величины, и действия по переводу вектора $D$ в вектор $U$ выполняется над полями этой структуры (листинг~\ref{lst:text_4_vec_ibm_list_of_struct}).

\begin{lstlisting}[caption={Организация данных в виде <<массив структур>>.},label={lst:text_4_vec_ibm_list_of_struct}]
struct Cell
{
    double rho;
    double u; double v; double w;
    double p;
    double rho_u; double rho_v; double rho_w;
    double E;
};
Cell cells[N];

void d_to_u()
{
    for (int i = 0; i < N; ++i)
    {
        double rho = cells[i].rho;
        double u = cells[i].u;
        double v = cells[i].v;
        double w = cells[i].w;
        double p = cells[i].p;

        cells[i].rho_u = rho * u;
        cells[i].rho_v = rho * v;
        cells[i].rho_w = rho * w;
        cells[i].E = 0.5 * rho * (u * u + v * v + w * w)
                     + p / (GAMMA - 1.0);
    }
}
\end{lstlisting}

При попытке векторизации цикла из листинга~\ref{lst:text_4_vec_ibm_list_of_struct} во время объединения $w$ итераций вместо чтения из памяти скалярного значения (например, плотности) должно происходить чтение значений плотности из несколько последовательно расположенных структур данных.
То есть чтение вектора плотностей должно осуществляться не из последовательной области памяти.
Для таких целей в наборе векторных инструкций AVX-512\label{abbr:avx-10} предусмотрены инструкции gather/scatter, однако их эффективность гораздо ниже чтения последовательной области памяти размера 512 бит даже при использовании предварительной подкачки данных.
И хоть организация данных виде <<массива структур>> наиболее предпочтительная с точки зрения идеологии объектно-ориентированного программирования, она оказывается непригодной для успешного применения векторизации.

Естественным решением оптимизации вычислений является организация расположения данных в памяти в виде набора массивов (листинг~\ref{lst:text_4_vec_ibm_set_of_lists}).
Теперь после объединения нескольких итераций цикла команды скалярного доступа в память трансформируются в векторные аналоги доступа к последовательной области памяти размера 512 бит.
Вся же арифметика, которая присутствует в коде функции, имеет свои векторные аналоги в наборе инструкций AVX-512.

\begin{lstlisting}[caption={Организация данных в виде <<набор массивов>>.},label={lst:text_4_vec_ibm_set_of_lists}]
double rhos[N];
double us[N]; double vs[N]; double ws[N];
double ps[N];
double rho_us[N]; double rho_vs[N]; double rho_ws[N];
double Es[N];

void d_to_u()
{
    for (int i = 0; i < N; ++i)
    {
        double rho = rhos[i];
        double u = us[i];
        double v = vs[i];
        double w = ws[i];
        double p = ps[i];

        rho_us[i] = rho * u;
        rho_vs[i] = rho * v;
        rho_ws[i] = rho * w;
        Es[i] = 0.5 * rho * (u * u + v * v + w * w)
                + p / (GAMMA - 1.0);
     }
}
\end{lstlisting}

Другой критической проблемой, влияющей на эффективность векторизации кода, является наличие условных операций внутри векторизуемого цикла.
Конечно набор инструкций AVX-512 содержит специальные масочные аргументы, с помощью которых можно векторизовать программный код с управлением практически любой сложности, однако при увеличении количества условий в коде эффективность векторизации снижается.
В качестве примера такого негативного эффекта можно рассмотреть логику гнезда циклов из функции \texttt{calc\_flows}, в которой корректируются газодинамические величины $U = [\rho, \rho u, \rho v, \rho w, E]$ с помощью потоков через все грани ячейки.
Если рассматриваемая расчетная область представлена структурированной сеткой размера $NX \times NY \times NZ$ по направлениям $i$, $j$, $k$ соответственно, то при учете потоков через левую грань каждой ячейки необходимо отдельно обрабатывать случай $i = 0$, что соответствует граничному условию расчетной области (см. листинг~\ref{lst:text_4_vec_ibm_nest}).
Аналогично нужно рассматривать особые случаи для всех шести граней ячейки, что увеличивает количество условий внутри цикла и снижает эффективность векторизации.

\begin{lstlisting}[caption={Гнездо циклов с условием во внутреннем цикле.},label={lst:text_4_vec_ibm_nest}]
for (int k = 0; k < NZ; ++k)
{
    for (int j = 0; j < NY; ++j)
    {
        for (int i = 0; i < NX; ++i)
        {
            if (i == 0)
            {
                // left boundary condition
                ...
            }

            // rest code
            ...
        }
    }
}
\end{lstlisting}

Можно заметить, что все три цикла гнезда (по индуктивным переменным $i$, $j$, $k$) не содержат межитерационных зависимостей, они могут быть переставлены в произвольном порядке, как и итерации внутри любого из них.
Также можно заметить, что условия обработки границ расчетной области не являются уникальными для тройки координат ячейки $(i, j, k)$, но являются константными для некоторого среза ячеек сетки.
Это означает, что для гнезда циклов такое условие является частично константным, и гнездо может быть разбито по этому условию (с помощью расщепления цикла по условию).
На листинге~\ref{lst:text_4_vec_split_nest} продемонстрировано разбиение гнезда циклов по условию $i = 0$, после чего итоговое гнездо, содержащее основную часть вычислений, освобождается от условия.
Аналогичным образом можно выполнить разбиение по остальным условиям, освободив от них основное гнездо циклов, которое после этого успешно векторизуется.

\begin{lstlisting}[caption={Расщепление гнезда циклов по условию.},label={lst:text_4_vec_split_nest}]
for (int k = 0; k < NZ; ++k)
{
    for (int j = 0; j < NY; j++)
    {
        // left boundary condition with i = 0
        ...
    }
}

for (int k = 0; k < NZ; ++k)
{
    for (int j = 0; j < NY; ++j)
    {
        for (int i = 1; i < NX; ++i)
        {
            // rest code
            ...
        }
    }
}
\end{lstlisting}

При таком расщеплении циклов по условию нарушается условие выровненности данных внутри цикла, то есть цикл становится квазиплоским.

На рис~\ref{fig:text_4_ibm_immersed_boundary_method_cheme} представлена общая схема выполнения одной итерации расчетов.
Основными функциями в этих расчетах являются \texttt{approximate\_values}, \texttt{d\_to\_u}, \texttt{calc\_fgh}, \texttt{calc\_flows}, \texttt{u\_to\_d}.
Все эти функции содержат внутри себя обработку ячеек расчетной сетки в гнезде циклов либо в одном цикле.
Функция \texttt{approximate\_values} выполняет апроксимацию газодинамических величин в фиктивных ячейках, содержит векторные и матричные операции и сложное управление.
Функции \texttt{d\_to\_u}, \texttt{calc\_fgh}, \texttt{u\_to\_d} не содержат операторов передачи управления и при условии реорганизации данных в виде <<набор массивов>> могут быть представлены в виде композиции плоских циклов.
Функция \texttt{calc\_flows} с помощью расщепления гнезда циклов по 6 условиям может быть предствлена в виде композиции квазиплоских циклов.

Для автоматически векторизованного с помощью оптимизирующего компилятора icc программного кода расчета газодинамического потока с помощью схемы Стегера-Уорминга и метода погруженной границы был поставлен эксперимент по замеру ускорения и эффективности векторизации на микропроцессоре Intel Xeon Phi KNL.
Во время проведения эксперимента на модельной задаче был собран профиль исполнения до векторизации и после нее, результаты распределения времени исполнения между этими основными функциями представлены на рис.~\ref{fig:text_4_ibm_diagr}.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./fig/vec_ibm_diagr.png}
\singlespacing
\captionstyle{center}\caption{Распределение времени выполнения отдельных функций газодинамического решателя.}
\label{fig:text_4_ibm_diagr}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./fig/vec_ibm_diagr2.png}
\singlespacing
\captionstyle{center}\caption{Ускорение кода и эффективность векторизации отдельных функций газодинамического решателя.}
\label{fig:text_4_ibm_diagr2}
\end{figure}

Также на рис.~\ref{fig:text_4_ibm_diagr2} представлены результаты ускорения и эффективности векторизации каждой функции.
Ускорение различных функций в результате векторизации сильно отличается друг от друга.
Причиной этому являются конкретные особенности каждой из этих функций.

Наибольшее ускорение продемонстрировала функция \texttt{calc\_fgh} вычисления потоков $F^{\pm}$, $G^{\pm}$, $H^{\pm}$.
Функция содержит плоский цикл, полностью удовлетворяющий всем условиям, что делает возможным замену всех скалярных операций на векторные аналоги.
В скалярной версии используются библиотечные вызовы \texttt{abs} и \texttt{sqrt}, имеющие векторные аналоги в наборе AVX-512.
Обилие операций умножения и сложения делает возможным применение векторных комбинированных операций вида $\pm a \cdot b \pm c$.

Также ускорение выше среднего продемонстрировали функции \texttt{d\_to\_u} и \texttt{u\_to\_d}.
Эти функции также состоят из плоских циклов, поэтому скалярные операции могут быть заменены на векторные аналоги.
Более низкое ускорение функции \texttt{u\_to\_d} объясняется наличием операций деления, которые выполняются медленнее операций сложения и умножения.

Показатель ускорения функции \texttt{calc\_flows} составил менее двух раз даже после избавления от всех условий, связанных с обработкой границ расчетной области.
Такая низкая эффективность векторизации объясняется тем, что внутри этой функции присутствуют циклы, которые не являются плоскими.
Так, например, в функции \texttt{calc\_flows} для корректировки консервативных величин внутри ячейки $(i, j, k)$ требуется обращаться за данными ко всем смежным по граням ячейкам: $(i \pm 1, j, k)$, $(i, j \pm 1, k)$, $(i, j, k \pm 1)$.
Это нарушает требование по унификации обращения к массивам данных на одной итерации плоского цикла и немедленно приводит к появлению операций gather/scatter, понижая эффективность векторизации.
Для функции \texttt{approximate\_values} ситуация выглядит аналогичной, так как для выполнения аппроксимации данных в ячейке $(i, j, k)$ требуется обращаться за данными в ячейки, относящиеся к шаблону аппроксимации (на рис~\ref{fig:text_4_ibm_immersed_boundary_method_cheme} нарушение требования унификации обращения за данными продемонстрировано красными стрелками, означающими, что при обработке одной ячейки сетки мы вынуждены обращаться за данными к другой ячейке).

%---------------------------------------------------------------------------------------------------
% 5.4 - вынос маловероятных регионов
% Локализация маловероятных регионов и т.п.

\subsection{Векторизация с помощью выноса маловероятных регионов из плоского цикла}\label{sec:text_4_loc_branch}

В этом разделе рассматривается оптимизация выноса маловероятного региона из плоского цикла.
Инструкции передачи управления не имеют векторных аналогов.
Наличие команд передачи управления по условию в теле плоского цикла является основной причиной потери производительности при векторизации.
При наличии большого количества операторов управления оптимизирующий компилятор либо создает крайне неэффективный векторный код, либо вообще отказыватся от векторизации из-за слишком низкого ожидания ускорения \cite{Rybakov2018VecBranch}.
В процессе исполнения не весь код в теле векторизуемого цикла одинаково вероятен.
Если в теле присутствуют явно низковероятные регионы (если вероятности всех входящих в регион ребер близка к нулю), то можно выполнить их вынос из цикла, а оставшийся код в теле цикла может быть векторизован либо автоматически, либо с минимальными усилиями.

\subsubsection{Вынос маловероятного региона из плоского цикла}

Рассмотрим оптимизацию выноса маловероятного региона из цикла с помощью временного сохранения условия.
Пусть есть плоский цикл, записанный в виде, представленном на листинге~\ref{lst:text_4_vec_loc_branch_1}.

\begin{lstlisting}[caption={Плоский цикл с маловероятным регионом.},label={lst:text_4_vec_loc_branch_1}]
for (int i = 0; i < w; ++i)
{
    block(i);
    
    if (cond(i))
    {
        block_true(i); //  prob. ~1.0
    }
    else
    {
        block_false(i); // prob. ~0.0
    }
}
\end{lstlisting}

В плоском цикле на листинге~\ref{lst:text_4_vec_loc_branch_1} внутри его тела мы видим три блока с кодом.
Блок кода \texttt{block(i)} выполнятся в начале тела цикла.
Далее в зависимости от условия \texttt{cond(i)} выполняется либо блок кода \texttt{block\_true(i)} с вероятностью около единицы, либо блок \texttt{block\_false(i)} с вероятностью около нуля.
Пусть блоки \texttt{block(i)} и \texttt{block\_true(i)} являются простым по структуре и пригодным для векторизации, а блок \texttt{block\_false(i)} -- маловероятный и крайне непригодный для векторизации.
В исходном виде компилятор, как правило, не справляется с векторизацией такого цикла, поэтому для его автоматической векторизации можно использовать преобразование исходного кода, связанное с расщеплением этого цикла по условию.
Для этого создадим вместо одного цикла три новых.
В первом цикле будет выполняться только блок \texttt{block(i)}, после которого все условия \texttt{cond(i)} записываются в локальный массив булевых значений.
Во втором цикле на каждой итерации при истинном значении элемента \texttt{TMP[i]} выполняется ветка кода из блока \texttt{block\_true(i)}.
Третий цикл инкапсулирует в себе выполнение маловероятного кода при условии ложности соответствующих значений \texttt{TMP[i]}.

\begin{lstlisting}[caption={Расщепление плоского цикла с маловероятным регионом.},label={lst:text_4_vec_loc_branch_2}]
for (int i = 0; i < w; ++i)
{
    block(i);
    TMP[i] = cond(i);
}

for (int i = 0; i < w; ++i)
{
    block_true(i) ? TMP[i];
}

if (TMP != 0x0)
{
    for (int i = 0; i < w; ++i)
    {
        if (!TMP[i])
        {
            block_false(i);
        }
    }
}
\end{lstlisting}

В результате выполненных преобразований первый цикл из листинга~\ref{lst:text_4_vec_loc_branch_2} содержит только векторизуемый безусловный код, второй цикл также содержит векторизуемый код, но с использованием предиката, который при векторизации преобразуется в векторную маску, накладываемую на все операции этого цикла.
Третий код является маловероятным и его вообще не требуется оптимизировать (дополнительно перед его выполнением следует проверить маску на наличие в ней ложных элементов, что также в большинстве случаев избавит от необходимости выполнять все итерации цикла).
В результате схематично векторизованная версия всех трех циклов будет выглядеть так, как это представлено на листинге~\ref{lst:text_4_vec_loc_branch_3}.

\begin{singlespace}
\begin{lstlisting}[caption={Векторизованная версия расщепленного плоского цикла с маловероятным регионом.},label={lst:text_4_vec_loc_branch_3}]
BLOCK();
TMP = COND();
BLOCK_TRUE() ? TMP;

if (TMP != 0x0)
{
    for (int i = 0; i < w; ++i)
    {
        if (!TMP[i])
        {
            block_false(i);
        }
    }
}
\end{lstlisting}
\end{singlespace}

Это преобразование следует использовать при уверенности, что условие \texttt{cond(i)} является вероятным.
При значении вероятности этого условия, близкой к единице, логическое ускорение от применения векторизации будет близко к ширине векторизации (при условии, что \texttt{block(i)} и \texttt{block\_true(i)} векторизуются идеально).
Однако, если условие \texttt{cond(i)} не является вероятным, то выполнение такого преобразования приведет к деградации производительности.
Также это преобразование применимо только если все выходы из выносимого региона являются выходами с итерации плоского цикла.

\subsubsection{Эксперимент по выносу маловероятного региона}

В разделе~\ref{sec:text_1_geo_prim_line_eps_intersect} приведено описание задачи нахождения пересечения прямой с окрестностью отрезка в пространстве.
Эта задача имеет практическое значение в авиации применительно к обеспечению безопасности полетов воздушных судов.
Во время полета летательный аппарат (ЛА\label{abbr:la-1}) генерирует вихревой спутный след \cite{Aubakirov1999Wake}, который со временем эволюционирует и конечном итоге разрушается.
Этот след может представлять опасность для других участников воздушного движения \cite{Babkin2008Wake}.
Вихревой след может быть описан как совокупность окрестностей отрезков траектории движения.
Для определения конфликта требуется решить задачу наличия пересечения траектории движения собственного ЛА в виде полупрямой с множеством окрестностей отрезков.
При этом наличие хотя бы одного конфликта является редкой исключительной ситуацией.
Если рассматривать поставленную задачу в виде плоского цикла, то вероятной ветвью исполнения в нем будет анализ на наличие пересечения, а маловероятной -- нахождения самих точек пересечения и принятие решения об избежании конфликта \cite{Rybakov2017Flight,Rybakov2022VecGeom}.

Вернемся к задаче пересечения траектории собственного ЛА с окрестностью отрезка движения другого ЛА из раздела~\ref{sec:text_1_geo_prim_line_eps_intersect}.
Рассмотрим неравенство \eqref{eqn:text_1_geo_prim_ineq_k2k1k0} и случай $k_2 < 0$, или более подробно $k_2 = (\Delta \overline{C}, \overline{V})^2 + |\overline{V}|^2 \left( \Delta R^2 - |\Delta \overline{C}|^2 \right) < 0$.
Раскрыв скалярное произведение векторов и выполнив необходимые преобразования, получим условие на угол между тректорией движения собственного ЛА и отрезком $AB$: $\left| \sin{\angle(\Delta \overline{C}, \overline{V})} \right| > \frac{|\Delta R|}{|\Delta \overline{C}|}$, где $\frac{|\Delta R|}{|\Delta \overline{C}|}$ представляет собой синус угла раствора окрестности отрезка $AB$.
Заметим, что угол раствора всегда очень мал, так как характеристики ЛА меняются медленно во время движения, и $\Delta R$ близко к нулю.
Таким образом, случай $k_2 < 0$ выполняется в подавляющем большинстве случаев.

Но даже в случае $k_2 < 0$ множество решений неравенства \eqref{eqn:text_1_geo_prim_ineq_k2k1k0} на отрезке $[0, 1]$ в подавляющем числе случаев оказывается пустым.
Переписав условие отсутствия решения \eqref{eqn:text_1_geo_prim_ineq_k2k1k0} на отрезке $[0, 1]$ при условии $k_2 < 0$ получим практически всегда выполняющееся условие $(k_2 < 0) \land (m > 0) \land (k_1^2 - k_2k_0 < m^2)$, где $m = \max(k_1 + k_2, -k_1)$.
С использованием этого условия как вероятного для выноса маловероятной ветви исполнения из плоского цикла, был поставлен эксперимент по векторизации программного кода определения конфликтов со спутными следами ЛА.
В результате к основному циклу была применена автоматическая векторизация и было достигнуто ускорение в районе 5,1 раз на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-8} при использовании вещественных чисел формата fp32.

%---------------------------------------------------------------------------------------------------
% 5.5 - слияние

\subsection{Векторизация с помощью слияния путей исполнения}\label{sec:vec_mrg}

В этом разделе рассматривается оптимизация слияния путей исполнения по условию внутри плоского цикла с помощью постановки операций из параллельных скалярных блоков под предикаты этих блоков, трансформирующиеся при векторизации в векторные маски.
Приводятся аналитические оценки логической эффективности векторизации плоского цикла, в котором выполняется слияние двух скалярных блоков.

\subsubsection{Слияние по условию}\label{sec:text_4_vec_mrg_under_cond}

Универсальным способом векторизации программного кода с условиями является слияние всех путей исполнения под соответствующими предикатами \cite{Rybakov2024VecComb}.
Рассмотрим это действие на примере простого условия \texttt{cond}, по результату которого выполняется переход на один из блоков \texttt{block A} и \texttt{block B}.
Пусть известны вероятности переходов на эти блоки -- они равны $p$ и $1 - p$ соответственно.
Длины рассматриваемых блоков нормируем так, чтобы в сумме они давали единицу, а отношение их длин задавалось параметром $\alpha$, то есть они равны $\frac{\alpha}{\alpha + 1}$ и $\frac{1}{\alpha + 1}$ соответственно (см. рис.~\ref{fig:text_4_vec_mrg_under_cond} слева).
Условимся считать, что длина блока и время его исполнения это по сути одно и то же.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./fig/vec_ifconv.pdf}
\singlespacing
\captionstyle{center}\caption{Схема векторизации программного кода с условием при помощи простого слияния (слева) и с проверкой масок на пустоту (справа).}
\label{fig:text_4_vec_mrg_under_cond}
\end{figure}

Согласно схеме на рис.~\ref{fig:text_4_vec_mrg_under_cond} слева математическое ожидание времени исполнения рассматриваемых блоков в зависимости от условия, будет равно
\begin{equation}\label{eqn:text_4_vec_mrg_under_cond_t1}
	L = \frac{p \alpha}{\alpha + 1} + \frac{1 - p}{\alpha + 1} = p\left(\frac{\alpha - 1}{\alpha + 1}\right) + \left(\frac{1}{\alpha + 1}\right).
\end{equation}

Время выполнения $w$ таких участков кода в невекторизованном виде будет равно $wL$.
При векторизации кода необходимо избавиться от операций перехода, вместо этого все операции блоков \texttt{block A} и \texttt{block B} должны быть поставлены под предикаты \texttt{cond} и \texttt{\textasciitilde cond} соответственно.
Далее выполняется объединение $w$ блоков, при котором скалярные операции под предикатами \texttt{cond}, \texttt{\textasciitilde cond} заменяются на векторные аналоги, выполняющиеся с использованием векторных масок \texttt{COND}, \texttt{\textasciitilde COND}.
Так как длины блоков выбирались таким образом, чтобы в сумме они давали единицу, то время исполнения векторной версии кода в точности равно $L_v = 1$.
То есть логическая эффективность векторизации рассмотренного фрагмента кода совпадает со значением \eqref{eqn:text_4_vec_mrg_under_cond_t1} и равна
\begin{equation}\label{eqn:text_4_vec_mrg_under_cond_e}
	e_{vec}^{*} = \frac{L}{L_v} = p\left(\frac{\alpha - 1}{\alpha + 1}\right) + \left(\frac{1}{\alpha + 1}\right).
\end{equation}

На рис.~\ref{fig:text_4_vec_under_cond_chart_e_merged} слева представлены графики зависимостей логической эффективности векторизации из \eqref{eqn:text_4_vec_mrg_under_cond_e} для разных значений параметра $\alpha$.

\begin{figure}[ht]
\centering
\begin{tabular}{ll}
\includegraphics[width=0.45\textwidth]{./fig/vec_ifconv_nocheck_chart.png}
& 
\includegraphics[width=0.45\textwidth]{./fig/vec_ifconv_check_chart.png}
\end{tabular}
\singlespacing
\captionstyle{center}\caption{Графики зависимостей $e_{vec}^{*}(p)$ при фиксированных значениях $\alpha$ для простого слияния (слева) и с проверкой масок на пустоту (справа).}
\label{fig:text_4_vec_under_cond_chart_e_merged}
\end{figure}

Из рис.~\ref{fig:text_4_vec_under_cond_chart_e_merged} слева видно, что при $\alpha = 1$ (то есть при одинаковых длинах блоков \texttt{block A} и \texttt{block B}) эффективность векторизации постоянна и равна $0,5$.
В тех же случаях, когда длины блоков отличаются, эффективность векторизации возрастает, если вероятность перехода на более длинный блок выше, чем на более короткий блок.
В любом случае, такой подход прямого слияния ветвей исполнения под соответствующими предикатами в единый линейный участок является крайне неэффективным.
При возрастании количества условий эффективность векторизации таким способом падает экспоненциально.
Это связано с появлением в программном коде большого количества векторных инструкций с практически пустыми масками.
Для повышения эффективности векторизации контекста с условиями требуется рассмотрение других подходов, позволяющих повысить плотность масок исполняемых векторных команд.

Рассмотрим модификацию слияния путей исполнения, добавив проверку на пустоту векторых масок \texttt{COND} и \texttt{\textasciitilde COND}, под которыми исполняются векторизованные блоки \texttt{BLOCK A} и \texttt{BLOCK B} \cite{Rybakov2024VecComb} (см. рис.~\ref{fig:text_4_vec_mrg_under_cond} справа).

Если векторная маска, под которой должен быть исполнен блок, пуста, то выполнять команды этого блока нет необходимости, поэтому проверка векторных масок на пустоту может повысить эффективность векторного кода.
Использование проверок векторных масок на пустоту оправдано, если вероятность появления пустых масок достаточно высока, а также исполняемый блок не является коротким (в этом случае накладные расходы на лишнюю операцию сравнения и возможный переход нивелируют потенциальную пользу от применяемой оптимизации).
Скорректируем выражение для логической эффективности векторизации из \eqref{eqn:text_4_vec_mrg_under_cond_e} с учетом проверок векторных масок на пустоту.
Величина $L$ остается той же, что и в \eqref{eqn:text_4_vec_mrg_under_cond_t1}, а вот $L_v$ несколько изменится.
Если считать, что в каждом наборе обрабатываемых данных переход на тот или иной блок является случайной величиной, то вероятность пустой маски \texttt{COND} будет равна $(1 - p)^w$, тогда как вероятность пустой маски \texttt{\textasciitilde COND} равна $p^w$.
Тогда общая длина векторизованного кода может быть выражена как
\begin{equation}\label{eqn:text_4_vec_check_mask_tw}
	L_v = \left(1 - (1 - p)^w\right)\left(\frac{\alpha}{\alpha + 1}\right) + (1 - p^w)\left(\frac{1}{\alpha + 1}\right),
\end{equation}
а логическая эффективность векторизации примет следующий вид:
\begin{equation}\label{eqn:text_4_vec_check_mask_e}
	e_{vec}^{*} = \frac{ p(\alpha - 1) + 1 }{\left(1 - (1 - p)^w\right) \alpha + (1 - p^w) }.
\end{equation}

На рис.~\ref{fig:text_4_vec_under_cond_chart_e_merged} справа представлены зависимости логической эффективности векторизации \eqref{eqn:text_4_vec_check_mask_e} при разных значениях параметра $\alpha$ с учетом проверок масок на пустоту для ширины векторизации $w = 16$, что соответствует использованию вещественного формата данных одинарной точности в 512-битных регистрах.

Из рис.~\ref{fig:text_4_vec_under_cond_chart_e_merged} справа видно, что эффективность векторизации возрастает, если значение вероятности перехода на один из блоков близко к единице, однако в среднем вероятность векторизации остается невысокой.

%---------------------------------------------------------------------------------------------------
% 5.6 - объединение и комбинирование

% Комбинирование векторных масок.
\subsection{Векторизация с объединением и комбинированием векторных масок}\label{sec:text_4_comb_mask}

При векторизации плоского цикла $w$ соседних скалярных итераций объединяются в один векторизованный векторный блок, таким образом $n$ итераций плоского цикла транформируются в $\lfloor \frac{n}{w} \rfloor$ векторных блоков без учета эпилога.
Слияние путей исполнения по условию порождает векторные блоки под векторными масками, таким образом образуются последовательности одинаковых векторных блоков под векторными масками.
В этом разделе рассматривается повышение плотности масок векторного кода с помощью объединения и комбинирования масок соседних векторных блоков.
В общем случае без учета комбинированных операций общее количество выполненных операций скалярного кода выражается как $L = w \sum_{c \in C_v}{\rho(m(c))}$, где $C_v$ -- множество выполненных векторных инструкций в векторном коде, $m(c)$ -- маска инструкции, $\rho(m)$ -- плотность маски.
Таким образом, для повышения эффективности векторизации требуется повышение плостности векторных масок.

В результате слияния под соответствующими предикатами ветвей исполнения внутри тела плоского цикла мы получаем совокупность векторных блоков, обрабатывающихся сходим образом: загрузка входных данных \texttt{in\_data} под маской векторного блока, выполнение вычислений \texttt{block} под маской блока, сохранение результатов \texttt{out\_data} под маской блока (см. рис.~\ref{fig:text_4_vec_comb_mask_vec_block}).
На этой схеме \texttt{in\_data} и \texttt{out\_data} могут являться как одиночными векторами, так и наборами векторов.

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{./fig/vec_block_under_mask.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычислений векторизованного блока команд с входными данными \texttt{in\_data}, выходными данные \texttt{out\_data} и маской исполнения \texttt{0xEA}.}
\label{fig:text_4_vec_comb_mask_vec_block}
\end{figure}

Проверка маски блока на пустоту может повысить эффективность кода, если маски часто оказываются пустыми.
Однако это не поможет в том случае, если в маске выставлено несколько битов.
В некоторых случаях достичь повышения производительности можно путем объединения двух соседних векторных блоков \cite{Rybakov2024VecComb}.

\subsubsection{Объединение непересекающихся масок}

Если в процессе векторизации у нас появились два соседних векторных блока \texttt{block(in\_data\_1)} $\rightarrow$ \texttt{out\_data\_1} и \texttt{block(in\_data\_2)} $\rightarrow$ \texttt{out\_data\_2}, которые должны выполняться под разными векторными масками \texttt{mask\_1} и \texttt{mask\_2}, и в дополнение к этому для этих масок выполнено условие \texttt{(mask\_1 \& mask\_2) == 0x0} (то есть маски не пересекаются), то вычисление этих двух соседних блоков можно объединить.
Вместо последовательного выполнения двух векторных блоков можно объединить их входные данные \texttt{in\_data\_1} и \texttt{in\_data\_2} с помощью слияния \texttt{in\_data = \_mm512\_mask\_blend\_ps(mask\_1, in\_data\_2, in\_data\_1}), после чего выполнить тот же блок вычислений под маской \texttt{mask\_1 | mask\_2}.
Ввиду отсутствия пересечения векторных масок в результирующих выходных данных \texttt{out\_data} будут содержаться как необходимые элементы данных \texttt{out\_data\_1}, так и необходимые элементы данных \texttt{out\_data\_2}.
В конце остается извлечь из объединенного результата \texttt{out\_data} данные \texttt{out\_data\_1} и \texttt{out\_data\_2} (см. рис.~\ref{fig:text_4_vec_comb_mask_comb_masks}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./fig/vec_masks_union.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычислений с объединением двух векторных блоков \texttt{block(in\_data\_1)} $\rightarrow$ \texttt{out\_data\_1}, \texttt{block(in\_data\_2)} $\rightarrow$ \texttt{out\_data\_2}.
Объединение допустимо, так как векторные маски \texttt{0xCC00} и \texttt{0xEA} не пересекаются, объединенный блок выполняется под маской \texttt{0xCCEA}.}
\label{fig:text_4_vec_comb_mask_comb_masks}
\end{figure}

В результате такого преобразования в случае отсутствия пересечения векторных масок количество вычислений рассматриваемого блока \texttt{block} сокращается вдвое, а плотность векторных масок внутри блока повышается.
Однако вместе с этим появляются накладные расходы, связанные с проверками масок, а также операции слияния данных до вычислений блока и выделения нужных данных после вычислений.
Заметим, что эту технику можно применять для объединения трех и более соседних блоков, однако это связано с еще большим возрастанием накладных расходов.

\subsubsection{Комбинирование пересекающихся масок}

Еще один подход, о котором стоит упомянуть, но который не проверялся с точки зрения эффективности, связан с объединением соседних блоков с пересекающимися масками, то есть для которых \texttt{(mask\_1 \& mask\_2) != 0x0}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{./fig/vec_masks_comb.pdf}
\singlespacing
\captionstyle{center}\caption{Схема вычислений с объединением двух векторизованных блоков при условии пересечения их масок. Для объединения применяется изменение порядка элементов в данных одного из блоков.}
\label{fig:text_4_vec_comb_mask_comb_masks_perm}
\end{figure}

Если мы имеем дело с двумя масками низкой плотности, которые пересекаются, но для которых выполнено условие непревышения суммарной плотности ширины векторизации \texttt{popcnt(mask\_1) + popcnt(mask\_2) <= w}, то такие блоки также можно объединить.
Для этого перед объединением необходимо применять преобразование одной или обеих масок.

\begin{definition}
Преобразование \texttt{perm\_to} векторной маски \texttt{mask} называется обратимым, если существует преобразование \texttt{perf\_from} такое, что \texttt{perm\_from(perm\_to(mask)) = mask}.
\end{definition}

Для выполнения комбинирования векторных масок двух соседних блоков необходимо найти обратимое преобразование одной из масок (например, \texttt{mask\_1}) \texttt{perm\_to} такое, что будет выполнено условие \texttt{(perm\_to(mask\_1) \& mask\_2) == 0x0}.
В этом случае элементы входных данных переставляются местами в соответствии с преобразованием \texttt{perm\_to}, применяется объединение блоков, а для выходных данных выполняется перестановка элементов в соответствии с преобразованием \texttt{perm\_from} (см. рис.~\ref{fig:text_4_vec_comb_mask_comb_masks_perm}).

Отметитм следующие моменты.
Объединять можно не только два соседние блока, но также три и более, но это усложняет программный код и увеличивает накладные расходы.
Преобразование исходных масок можно применять не к одной из них, а сразу к обеим маскам.
В этом случае необходимо найти обратимое преобразование первой маски \texttt{perm\_to\_1} и обратимое преобразование второй маски \texttt{perm\_to\_2}, такие что будет выполнено условие \texttt{(perm\_to\_1(mask\_1) \& perm\_to\_2(mask\_2)) = 0x0}.

\subsubsection{Эксперимент по объединению векторных масок}\label{sec:text_4_comb_mask_analyze}

Был поставлен эксперимент по применению объединения векторных масок на примере функции \texttt{prefun} из газодинамического решателя (см. листинг~\ref{lst:text_4_vec_comb_prefun_scalar}).
Функция содержит одно условие и две ветви исполнения с достаточно тяжелыми вычислениями, что делает оправданным применение проверки масов на пустоту.
Операции в реализации функции имеют векторные аналоги в наборе интринсиков AVX-512\label{abbr:avx-11}, она может быть векторизована путем замены скалярных операций векторными аналогами и слияния ветвей исполнения.

\begin{singlespace}
\begin{lstlisting}[caption={Скалярная версия функции \texttt{prefun}.},label={lst:text_4_vec_comb_prefun_scalar}]
void scase_prefun_1(float& f, float& fd,
                    float p, float dk, float pk, float ck)
{
    if (p <= pk)
    {
        float prat = p / pk;
        f = riemann::sg4 * ck * (pow(prat, riemann::sg1) - 1.0f);
        fd = (1.0f / (dk * ck)) * pow(prat, -riemann::sg2);
    }
    else
    {
        float ak = riemann::sg5 / dk;
        float bk = riemann::sg6 * pk;
        float qrt = sqrt(ak / (bk + p));
        f = (p - pk) * qrt;
        fd = (1.0f - 0.5f * (p - pk) / (bk + p)) * qrt;
    }
}
\end{lstlisting}
\end{singlespace}

%\begin{singlespace}
%\begin{lstlisting}[caption={Векторизованная версия функции \texttt{prefun} из состава римановского решателя.},label={lst:text_4_vec_comb_prefun_vec}]
%void vcase_prefun_1(__m512& f, __m512& fd,
%                    __m512& p, __m512& dk, __m512& pk, __m512& ck,
%                    __mmask16 m)
%{
%  __mmask16 cond = _mm512_kand(_mm512_cmple_ps_mask(p, pk), m);
%  __mmask16 ncond = _mm512_kand(_mm512_knot(cond), m);
%
%  { // first branch
%    __m512 prat = _mm512_mask_div_ps(zero, cond, p, pk);
%    f = _mm512_mask_mul_ps(f, cond,
%          _mm512_mask_mul_ps(zero, cond, riemann::g4, ck),
%          _mm512_mask_sub_ps(zero, cond,
%            _mm512_mask_pow_ps(zero, cond, prat, riemann::g1),
%            one));
%    fd = _mm512_mask_mul_ps(fd, cond,
%           _mm512_mask_div_ps(zero, cond, one,
%             _mm512_mask_mul_ps(zero, cond, dk, ck)),
%           _mm512_mask_pow_ps(zero, cond, prat,
%             _mm512_mask_sub_ps(zero, cond, zero, riemann::g2)));
%  }
%  { // second branch
%    __m512 ak = _mm512_mask_div_ps(zero, ncond, riemann::g5, dk);
%    __m512 bk = _mm512_mask_mul_ps(zero, ncond, riemann::g6, pk);
%    __m512 qrt = _mm512_mask_sqrt_ps(zero, ncond,
%                   _mm512_mask_div_ps(zero, ncond, ak,
%                     _mm512_mask_add_ps(zero, ncond, bk, p)));
%      f = _mm512_mask_mul_ps(f, ncond,
%            _mm512_mask_sub_ps(zero, ncond, p, pk), qrt);
%      fd = _mm512_mask_mul_ps(fd, ncond,
%             _mm512_mask_sub_ps(zero, ncond, one,
%               _mm512_mask_mul_ps(zero, ncond, half,
%                 _mm512_mask_div_ps(zero, ncond,
%                   _mm512_mask_sub_ps(zero, ncond, p, pk),
%                   _mm512_mask_add_ps(zero, ncond, bk, p)))),
%             qrt); 
%  }
%}                 
%\end{lstlisting}
%\end{singlespace}

%В процессе векторизации не применялись никакие локальные оптимизации, все скалярные операции были строго заменены на векторные аналоги с сохранением порядка вычислений с точности до ассоциативности умножения.
%Из приведенного на листинге~\ref{lst:text_4_vec_comb_prefun_vec} кода видно, что команды первой ветви выполняются под маской \texttt{cond}, а другой ветви -- под маской \texttt{ncond}, таким образом можно применить проверку масок на пустоту.

В разделе~\ref{sec:vec_mrg} вычислялась вероятность появления пустой маски, и использовалось предположение, что выполнение условий для разных наборов скалярных данных являются независимыми событиями.
На самом деле это не так, и зависит от локальности размещения данных, участвующих в расчетах \cite{Rybakov2020VecMon}.
Рассмотрим условие \texttt{p <= pk}.
Элементы данных \texttt{p} и \texttt{pk} свои для каждой расчетной ячейки.
Если речь идет о физических расчетах, то значение элемента данных изменяется не слишком сильно при переходе от одной ячейки к соседней ячейке (см. рис.~\ref{fig:text_4_vec_comb_continuity}).

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{fig/vec_continuity.png}
\singlespacing
\captionstyle{center}\caption{Иллюстрация тенденции сохранения значения условия при переходе к соседним ячейками в расчетных задачах.}
\label{fig:text_4_vec_comb_continuity}
\end{figure}

Значение условия \texttt{p <= pk} при переходе от одной ячейки к соседней будет изменяться также не слишком быстро.
Но условие это дискретная величина, а это значит, что часто значение условия будет сохраняться при переходе к соседней ячейке.
Для функции \texttt{prefun} были собраны расчетные данные распределения плотности маски условия \texttt{p <= pk}, чтобы оценить вероятность появления пустых масок \texttt{cond} и \texttt{ncond}.
На рис.~\ref{fig:text_4_vec_comb_mask_independent_p} слева представлено распределение плотности масок в случае независимости условий для разных наборов скалярных данных.
Результаты распределения плотности маски \texttt{cond}, собранные по настоящему профилю исполнения векторного кода на реальных данных, представлены на рис.~\ref{fig:text_4_vec_comb_mask_independent_p} справа.

\begin{figure}[ht]
\centering
\begin{tabular}{ll}
\includegraphics[width=0.45\textwidth]{fig/vec_mask_distr_independent_p.png}
&
\includegraphics[width=0.45\textwidth]{fig/vec_mask_distr_real_p.png}
\end{tabular}
\singlespacing
\captionstyle{center}\caption{Гистограмма распределения количества единичных битов маски \texttt{cond} при условии, что все условия \texttt{p <= pk} для наборов скалярных данных являются независимыми (слева) и на реальном профиле исполнения (справа).}
\label{fig:text_4_vec_comb_mask_independent_p}
\end{figure}

Из рис.~\ref{fig:text_4_vec_comb_mask_independent_p} видно, что распределение плотностей масок на реальных данных совершенно не похоже на распределение, вычисленное в предположении о независимости условий переходов.
Можно заметить, что в реальном коде более четверти всех масок \texttt{cond} являются либо пустыми, либо полными (в этом случае пустой является маска \texttt{ncond}), а значит использование проверок масок на пустоту обосновано.

Для анализа полученных результатов были рассмотрены следующие три подхода к векторизации плоского цикла с условием.
В качестве базового метода векторизация принималось простое слияние путей исполнения под соответствующими предикатами с последующим объединением $w$ последовательных скалярных итераций в одну векторную (простое слияние).
Этот базовый метод сравнивался с двумя рассмотренными выше улучшениями: проверка масок блоков на пустоту (проверка масок) и слияние двух соседних блоков при условии отсутствия пересечения их масок (объединение масок).
Анализ эффективности применения преобразований рассматривался для функции \texttt{prefun} из реализации газодинамического римановского решателя.
Профиль исполнения функции собирался на задачах моделирования распада разрыва при различных начальных условиях \cite{Toh2024VecRiemann}.
Эффективность векторизации при выбранных подходах измерялась двумя способами: с помощью эмуляции векторных инструкций \cite{Rybakov2023VecShvindt} и на реальной машине (микропроцессор Intel Xeon Phi KNL).
Результаты сравнения представлены на рис.~\ref{fig:text_4_vec_comb_mask_res}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{./fig/vec_masks_union_res.png}
\singlespacing
\captionstyle{center}\caption{Результаты сравнения эффективности векторизации при простом слиянии, с проверкой масок и с объединением масок в режимах эмуляции и на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-9}.}
\label{fig:text_4_vec_comb_mask_res}
\end{figure}

Эксперимент показал, что в режиме эмуляции слияние ветвей исполнения привело к эффективности векторизации 0,6.
Использование проверки масок и объединения масок позволило повысить ее до 0,67 и 0,75 соответственно.
На реальной машине слияние путей исполнения позволило достичь эффективности 0,31, а использование проверок масок и объединения масок позволило повысить ее до 0,43 и 0,47 соответственно.

%---------------------------------------------------------------------------------------------------
% 5.7 - гнезда циклов

\subsection{Векторизация гнезд циклов}\label{sec:vec_nests}

В расчетных приложениях часто встречается код, в котором тело плоского цикла содержит другие циклы или гнезда циклов.
В этом разделе проводится анализ программного контекста, в котором тело плоского цикла содержит другой цикл, такую конструкцию будем называть <<плоский цикл / внутренний цикл>> (см. рис.~\ref{fig:vec_flat_loop_nest}).

\begin{figure}[!ht]
\centering
\includegraphics[width=0.85\textwidth]{fig/vec_flat_loop_nest.pdf}
\singlespacing
\caption{Схема векторизации стуктуры <<плоский цикл / внутренний цикл>>.}
\label{fig:vec_flat_loop_nest}
\end{figure}

При выполнении векторизации тело внутреннего цикла $block$, выполняемое по условию $cond$, переводится в векторный блок $BLOCK$, инструкции которого выполняются под маской $COND$, которая постепенно истощается пока не станет пустой.
При этом выполняется соотношение $I_v = \max_{i = 0}^{w - 1}{I(i)}$, где $I(i)$ -- количество итераций внутреннего цикла на $i$-ой итерации плоского цикла в скалярной версии, $I_v$ -- количество итераций внутреннего цикла в векторизованной версии.
Эффективность векторизации рассматриваемого программного кода зависит от характера изменения условия $cond$ (и соответственно количества итераций внутреннего цикла $I(i)$) при переходе между итерациями плоского цикла.
Слишком резкое изменения условия $cond$ между итерациями плоского цикла приводит к сильному изменению значений $I(i)$, что приводит к деградации производительности при векторизации структруры <<плоский цикл / внутренний цикл>>.
В терминах количества итераций справедлива следующая лемма.

\begin{lemma}\label{lem:vec_lem}
При векторизации структуры <<плоский цикл / внутренний цикл>>, верна оценка
\begin{equation}\label{eqn:vec_7_lemma_eqn_1}
e_{vec}^{*} \le e_{vec}^I,
\end{equation}
где $e_{vec}^I = \frac{ \sum_{i = 0}^{w - 1}{I(i)} }{I_v w}$.
При этом, если $I_v - \min_{i = 0}^{w - 1}{I(i)} \le \varepsilon$, то
\begin{equation}\label{eqn:vec_7_lemma_eqn_2}
e_{vec}^I \ge 1 - \frac{\varepsilon}{I_v}.
\end{equation}
\end{lemma}

Пусть $\lambda$ -- количество операций на одной итерации внутреннего цикла в скалярной версии, а $\lambda_v$ -- количество операций на одной итерации внутреннего цикла в векторной версии. 
Тогда $\frac{\lambda}{\lambda_v} \le 1$, равенство достигается при идеальной векторизации итерации внутреннего цикла.
Из этого следует оценка \eqref{eqn:vec_7_lemma_eqn_1}, так как
\begin{equation}
	e_{vec}^{*} = \frac{L}{L_v w} = \frac{\sum_{i = 0}^{w - 1}{\sum_{j = 0}^{I(i) - 1}{\lambda}}}{w \sum_{j = 0}^{I_v}{\lambda_v}} = \frac{\lambda \sum_{i = 0}^{w - 1}{I(i)}}{w \lambda_v I_v} = \frac{\lambda}{\lambda_v} e_{vec}^I \le e_{vec}^I.
\end{equation}

Так как $I_v - \min_{i = 0}^{w - 1}{I(i)} \le \varepsilon$, то $\forall i \in [0, w - 1] \implies I(i) \ge I_v - \varepsilon$, откуда следует вторая оценка
\begin{equation}
	e_{vec}^I = \frac{\sum_{i = 0}^{w - 1}{I(i)}}{I_v w} \ge \frac{(I_v - \varepsilon) w}{I_v w} = 1 - \frac{\varepsilon}{I_v}. \ \blacksquare
\end{equation}

Характеристику $e_{vec}^I$ из леммы~\ref{lem:vec_lem} можно назвать логической эффективностью векторизации в терминах количества итераций внутреннего цикла, а параметр $\varepsilon$ -- коэффициентом неравномерности распределения количества итераций внутреннего цикла в скалярной версии (если $\varepsilon = 0$, то все $I(i)$ равны между собой).
Далее анализируется влияние характера изменения условий $cond$ в структуре <<плоский цикл / внутренний цикл>> и распределения количества итераций внутреннего цикла в скалярной версии на эффективность векторизации.

\subsubsection{Внутренний цикл с постоянным количеством итераций}\label{sec:text_4_vec_mesh_intersect}

Рассмотрим программный контекст, в котором внутренний цикл, находящийся в теле плоского цикла, выполняется с постоянным количеством итераций, то есть $\varepsilon = 0$ и $e_{vec}^I = 1$.

В разделе~\ref{sec:text_1_immersed_boundary_method} приведен метод погруженной границы для выполнения газодинамических расчетов вокруг тела со сложной геометрией.
На первом этапе его реалиазации выполняется определение пересечения ячеек неструктурированной поверхностной расчетной сетки с ячейками объемной декартовой сетки, для чего многократно решается задача обнаружения пересечения треугольника и прямоугольного параллелепипеда в пространстве из раздела~\ref{sec:int_with_undermesh} (листинг~\ref{lst:text_1_mesh_intersect_tri}) с помощью свертывания системы линейных неравенств \cite{Chernikov1963}.

\begin{singlespace}
\begin{lstlisting}[caption={Определение пересечения треугольника и прямоугольного параллелепипеда с помощью свертывания системы линейных неравенств.},label={lst:text_1_mesh_intersect_tri}]
for (i = 0; i < bec; ++i)
{
    gi0 = g[i][0];

    if (gi0 == 0.0)
    {
        if (!upgrade(g[i][1], g[i][2], &lo, &hi)) return 0;
    }
    else
    {
        for (j = i + 1; j < bec; ++j)
        {
            if (gi0 * g[j][0] < 0.0)
            {
                f0 = gi0 * g[j][1] - g[j][0] * g[i][1];
                f1 = gi0 * g[j][2] - g[j][0] * g[i][2];

                if (gi0 < 0.0)
                {
                    f0 = -f0;
                    f1 = -f1;
                }

                if (!upgrade(f0, f1, &lo, &hi)) return 0;
            }
        }
    }
}

return 1;
\end{lstlisting}
\end{singlespace}

Код с листинга~\ref{lst:text_1_mesh_intersect_tri} возвращает 1 при наличии пересечения.
Коэффициенты системы неравенств \eqref{eqn:text_1_geo_prim_2} заданы в массиве \texttt{g} размера $9 \times 3$.
Допустимые значения переменной $\gamma$ представлены отрезком \texttt{[lo, hi]}, который изменяется внутри функции \texttt{upgrade} в процессе выполнения одного шага свертывания.
Возникновение условия \texttt{lo > hi} означает отсутствие пересечения.

Получившийся программный код можно охарактеризовать как имеющий сложное управление с уровнем вложенности 5, несколькими выходами и вызовом функции.
Для векторизации $w$ экземпляров этого кода можно объединить в плоский цикл, рассматривая коэффициенты $w$ систем линейных неравенств, заданные в массиве размера $9 \times 3 \times w$.

Для эффективной векторизации необходимо избавляться от избыточных операций передачи управления.
Так как набор инструкций AVX-512 включает в себя векторизованные операции, реализующиеся через условия (операции abs, min, max, blend), то использование математических тождеств в некотороых случаях позволяет существенно упростить код.
Например, используя тождество $\forall a, b, c, d \in \mathbb{R} : ab < 0 \implies (a \ge 0) \ ? \ (ad - bc) : (bc - ad) = |a| d + |b| c$, вычисление значений \texttt{f0} и \texttt{f1} из строк 13-22 листинга~\ref{lst:text_1_mesh_intersect_tri} можно заменить на представленное на листинге~\ref{lst:vec_math_tozhdestv}.

\begin{singlespace}
\begin{lstlisting}[caption={Использование тождества для векторизации условия.},label={lst:text_4_mesh_intersect_tozh},label={lst:vec_math_tozhdestv}]
f0 = fabs(gi0) * g[j][1] + fabs(g[j][0]) * g[i][1]
f1 = fabs(gi0) * g[j][2] + fabs(g[j][0]) * g[i][2]
\end{lstlisting}
\end{singlespace}

Также цикл с листинга~\ref{lst:text_1_mesh_intersect_tri} можно расщепить по условию \texttt{gi0 == 0.0} со строки 5, получив отдельные цикл и гнездо, которые могут быть векторизованы независимо друг от друга.
Все внутренние циклы содержат фиксированное количество итераций (условие выхода -- достижение индуктивной переменной значения \texttt{bec}), таким образом, условия выхода из внутренних циклов не требуется векторизовать, они переносятся в векторный код в неизменном виде (общая схема векторизации представлена на рис.~\ref{fig:text_1_mesh_intersect_scheme}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_mesh_intersect_final_scheme.pdf}
\singlespacing
\captionstyle{center}\caption{Схема векторизации $w$ экземпляров кода свертывания \\ системы линейных неравенств.}
\label{fig:text_1_mesh_intersect_scheme}
\end{figure}

Из рис.~\ref{fig:text_1_mesh_intersect_scheme} видно, что рассматриваемый программный контекст достаточно просто переводится из скалярного вида в векторный.
Это происходит по причине следующих факторов: отсутствие избыточных условий, а также независимость условий выхода из внутренних циклов от номера итерации векторизуемого плоского цикла.
Также стоит обратить внимание на реализацию условного вызова функции \texttt{upgrade}, который заменяется на безусловный вызов с передачей условия внутрь нее для последующей векторизации.
В результате выполненных преобразований был получен эффективный векторный код для поиска пересечений поверхностной и объемной расчетных сеток.
Функция определения пересечения пар ячеек продемонстрировала ускорение в 6,7 раза по сравнению с невекторизованной версией на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-10}.
Полный код доступен в \cite{iparGithub}, а детальное описание преобразований кода можно найти в \cite{Rybakov2019VecInt}.

% Векторизация римановского решателя.
\subsubsection{Внутренний цикл с непостоянным количеством итераций}\label{sec:text_4_vec_riemann}

Если количество итераций внутреннего цикла не является постоянным и условия выхода из внутреннего цикла зависят от номера итерации плоского цикла, то такие условия необходимо переводить в векторную форму с использованием векторных предикатов.
Рассмотрим пример программного контекста, в котором количество итераций внутреннего цикла является непостоянным, однако значение характеристики $\varepsilon$ мало, а значение $e_{vec}^I$ близко к единице.
Такое поведение характерно для расчетных кодов компьютерного моделирования, в частности газодинамических решателей.
В \cite{Rybakov2019VecRiem1,Rybakov2019VecRiem2} рассмотрена векторизация точного римановского решателя, в которой $w$ экземпляров вызовов скалярного решателя $U = [d, u, p] = riem(U_l, U_r)$ ($U_l = [d_l, u_l, p_l]$, $U_r = [d_r, u_r, p_r]$ -- газодинамические параметры с двух сторон от разрыва) заменяется одним вызовом векторного решателя $\overline{U} = [\overline{d}, \overline{u}, \overline{p}] = riem(\overline{U}_l, \overline{U}_r)$, представленного в виде плоского цикла \cite{riemannvecGithub}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{fig/vec_riemann_functions.pdf}
\singlespacing
\captionstyle{center}\caption{Схема потока данных в римановском решателе}
\label{fig:text_4_vec_riem_functions}
\end{figure}

Наибольший интерес представляет функция \texttt{starpu}, содержащая цикл с неизвестным количеством итераций (листинг~\ref{lst:text_4_vec_riem_starpu}).

\begin{lstlisting}[caption={Скалярная версия функции \texttt{starpu}.},label={lst:text_4_vec_riem_starpu}]
void starpu(float dl, float ul, float pl, float cl,
            float dr, float ur, float pr, float cr, float &p, float &u)
{
    const int nriter = 20;
    const float tolpre = 1.0e-6;
    float change, fl, fld, fr, frd, pold, pstart, udiff;

    guessp(dl, ul, pl, cl, dr, ur, pr, cr, pstart);
    pold = pstart;
    udiff = ur - ul;

    int i = 1;
    for ( ; i <= nriter; i++)
    {
        prefun(fl, fld, pold, dl, pl, cl);
        prefun(fr, frd, pold, dr, pr, cr);
        p = pold - (fl + fr + udiff) / (fld + frd);
        change = 2.0 * abs((p - pold) / (p + pold));

        if (change <= tolpre) break;
        if (p < 0.0) p = tolpre;

        pold = p;
    }

    if (i > nriter)
    {
        cout << "divergence in Newton-Raphson iteration" << endl;
        exit(1);
    }

    u = 0.5 * (ul + ur + fr - fl);
}
\end{lstlisting}

Цикл, расположенный в строках 13-24 листинга~\ref{lst:text_4_vec_riem_starpu}, кроме неизвестного количества итераций содержит также операторы передачи управления и вызовы функций, что также усложняет его векторизацию.
Перед выполнением векторизации этот цикл необходимо преобразовать в предикатную форму, в которой тело не должно содержать операций передачи управления.
Заводится предикат выполнения итерации цикла, под который ставятся все инструкции тела цикла, а также который передается в вызовы функций \texttt{prefun}.
Тогда при векторизации предикат, под которым выполняется тело цикла, преобразуется в векторную маску, как это показано на листинге~\ref{lst:text_4_vec_riem_starpu_vec}, и векторизованный цикл прекращает работу либо в случае истощения этой маски, либо в случае превышения допустимого количества итераций (аварийная остановка) \cite{Krzikalla2026Vec}.

\begin{lstlisting}[caption={Векторизованная версия функции \texttt{starpu}.},label={lst:text_4_vec_riem_starpu_vec}]
void starpu_16(__m512 dl, __m512 ul, __m512 pl, __m512 cl,
               __m512 dr, __m512 ur, __m512 pr, __m512 cr,
               __m512 *p, __m512 *u)
{
    ...
    two = SET1(2.0); tolpre = SET1(1.0e-6); tolpre2 = SET1(5.0e-7);
    udiff = SUB(ur, ul);

    guessp_16(dl, ul, pl, cl, dr, ur, pr, cr, &pold);

    // Start with full mask.
    m = 0xFFFF;

    for (; (iter <= nriter) && (m != 0x0); iter++)
    {
        prefun_16(&fl, &fld, pold, dl, pl, cl, m);
        prefun_16(&fr, &frd, pold, dr, pr, cr, m);
        *p = _mm512_mask_sub_ps(*p, m, pold,
                 _mm512_mask_div_ps(z, m,
                     ADD(ADD(fl, fr), udiff), ADD(fld, frd)));
        change = ABS(_mm512_mask_div_ps(z, m,
                         SUB(*p, pold), ADD(*p, pold)));
        cond_break = _mm512_mask_cmp_ps_mask(m, change,
                         tolpre2, _MM_CMPINT_LE);
        m &= ~cond_break;
        cond_neg = _mm512_mask_cmp_ps_mask(m, *p, z, _MM_CMPINT_LT);
        *p = _mm512_mask_mov_ps(*p, cond_neg, tolpre);
        pold = _mm512_mask_mov_ps(pold, m, *p);
    }

    if (iter > nriter)
    {
        cout << "divergence in Newton-Raphson iteration" << endl;
        exit(1);
    }

    *u = MUL(SET1(0.5), ADD(ADD(ul, ur), SUB(fr, fl)));
}
\end{lstlisting}

На листинге~\ref{lst:text_4_vec_riem_starpu_vec} в строке 12 видна изначальная инициализация полной маски выполнения векторизованных итераций цикла.
По мере работы цикла маска истощается (строка 25), и при полном ее обнулении цикл завершает работу.
Эта же маска передается в векторизованную функцию \texttt{prefun\_16}, в которой все операции должны быть выполнены под этой маской.
Эффективность векторизации напрямую связана со скоростью изменения плотности векторной маски \texttt{m}.
Нетрудно видеть, что величина $\frac{\varepsilon}{I_v}$ соответствует доли количества итераций векторизованного цикла, на которых векторная маска \texttt{m} является неполной.

Для замеров эффективности векторизации функций точного римановского решателя на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-10-2} был поставлен численный эксперимент, в рамках которого запускалась скалярная и векторная версии кода на одном и том же наборе входных данных, полученных из прогона стандартных тестов для задачи распада разрыва \cite{Bulat2015VecRiemann}.
На диаграмме рис.~\ref{fig:text_4_vec_riemann_perf} показан эффект от применения различных оптимизаций к каждой из рассматриваемых функций, а также суммарное ускорение, полученное вследствие векторизации.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_riemann_perf.pdf}
\singlespacing
\captionstyle{center}\caption{Диаграмма ускорения отдельных функций и суммарного ускорения римановского решателя.}
\label{fig:text_4_vec_riemann_perf}
\end{figure}

Отметим, что ускорение от векторизации функции \texttt{starpu} составило примерно 4,4 раза, что скромнее результатов, продемонстрированных при векторизации гнезда циклов с постоянным количеством итераций из раздела~\ref{sec:text_4_vec_mesh_intersect}.
Ускорение от векторизации функции \texttt{starpu} оказалось ниже ускорения остальных функций решателя, которые содержат только арифметические вычисления и команды передачи управления.
Результат ускорения функции \texttt{sample} не является показательным, так как для нее применялись специальные преобразования, связанные с заменой переменных и удалением повторяющихся участков программного кода \cite{Rybakov2018VecBranch}.

% Векторизация циклов с нерегулярным количеством итераций.
\newpage
\subsubsection{Внутренний цикл с нерегулярным количеством итераций}\label{sec:text_4_vec_irreg}

В этом разделе рассматривается программный контекст, в котором на итерациях плоского цикла невозможно предсказать условие выхода из внутреннего цикла, что приводит к возникновению гнезд циклов с нерегулярным количеством итераций \cite{Rybakov2019VecIrr,Shabanov2019VecSci}, что характеризуется значением $\varepsilon$, сравнимым с $I_v$, и малым значением $e_{vec}^I$.

В качестве примера такого программного контекста рассмотрим реализацию сортировки Шелла, представляющую собой расширение сортировки вставками, которое работает быстрее, так как позволяет на ранних этапах упорядочить далеко расположенные друг от друга элементы массива, и это приводит к тому, что массив становится частично упорядоченным.
Во время сортировки Шелла выполняется последовательная сортировка подмассивов основного массива, являющихся срезами, при этом шаг среза постоянно уменьшается и на завершающем этапе выполняется обычная сортировка вставками (это соответствует срезу массива с шагом 1).
Выполнение сортировки срезов массива с большими шагами облегчает сортировку срезов с меньшими значениями шага, эффективность сортировки существенно зависит от выбранной последовательности шагов (примеры последовательностей шагов приведены в таблице~\ref{tbl:text_4_vec_irreg_steps}).

\begin{table}[h!]
\centering
\singlespacing
\captionstyle{center}\caption{Различные последовательности шагов, используемые в сортировке Шелла ($n$ -- размер массива).}
\bigskip
\label{tbl:text_4_vec_irreg_steps}
\begin{tabular}{ | c | c | }
  \hline
  Последовательность шагов & Формула \\ \hline\hline
  \makecell{Последовательность \\ Шелла}    & $k_1 = \lfloor \frac{n}{2} \rfloor, \ k_i = \lfloor \frac{k_{i-1}}{2} \rfloor, \ k_t = 1$ \\ \hline
  \makecell{Последовательность \\ Хиббарда} & $2^i - 1 \le n$, $i \in \mathbb{N}$ \\ \hline
  \makecell{Последовательность \\ Пратта}   & $2^i \cdot 3^j \le \frac{n}{2}$, $i \in \mathbb{N}$, $j \in \mathbb{N}$ \\ \hline
  \makecell{Последовательность \\ Седжвика} & $k_i = \begin{cases} 9 \cdot 2^i - 9 \cdot 2^{\frac{i}{2}} + 1, \ i = 2m, \ m \in \mathbb{Z}_{\ge 0} \\ 8 \cdot 2^i - 6 \cdot 2^{\frac{i + 1}{2}}, \ i = 2m + 1, \ m \in \mathbb{Z}_{\ge 0} \end{cases}$ \\ \hline
\end{tabular}
\end{table}

Реализация сортировки Шелла состоит из гнезда циклов, содержащего три цикла.
Внешний цикл выполняется по всем шагам из используемой последовательности шагов, начиная с максимального и заканчивая шагом 1.
Два внутренних цикла осуществляют сортировку всех подмассивов, являющихся срезами исходного массива с текущим шагом $k$ (листинг~\ref{lst:text_4_vec_irreg_shell}).

\begin{lstlisting}[caption={Реализация сортировки Шелла.},label={lst:text_4_vec_irreg_shell}]
void shell_sort(float *m, int n, int *ks, int k_ind)
{
    for (int k = ks[k_ind]; k > 0; k = ks[--k_ind])
    {
        for (int i = k; i < n; ++i)
        {
            float t = m[i];

            for (int j = i; j >= k; j -= k)
            {
                if (t < m[j - k]) m[j] = m[j - k];
                else break;
            }

            m[j] = t;
        }
    }
}
\end{lstlisting}

Рассмотрим возможности по векторизации сортировки Шелла для массива вещественных значений типа float (вектор AVX-512\label{abbr:avx-12} содержит 16 таких значений).
Самый вложенный цикл (цикл с счетчиком $j$, будем называть его просто внутренним) выполняет сортировку одного среза, состоящего из элементов массива, с расстоянием $k$ между соседними элементами.
Внутренний цикл не может быть векторизован без выполнения дополнительных модификаций кода, так как между записью элемента \texttt{m[j]} и чтением элемента \texttt{m[j - k]} существует межитерационная зависимость.
Две итерации среднего по вложенности цикла (цикла с индуктивной переменной $i$, будем называть его промежуточным) с номерами $i_1$ и $i_2$ не пересекаются по данным и могут быть выполнены параллельно при выполнении условия $|i_1 - i_2| < k$.
Выполним декомпозицию сортировки Шелла для того, чтобы можно было явно выделить ядро, поддающееся векторизации.

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{fig/vec_shell_code_decomp.pdf}
\singlespacing
\captionstyle{center}\caption{Декомпозиция сортировки Шелла для выделения векторизуемых участков кода.}
\label{fig:text_4_vec_irreg_code_decomp}
\end{figure}

На рис.~\ref{fig:text_4_vec_irreg_code_decomp} представлена схема декомпозиции сортировки Шелла, в которой выделены участки с разной максимально допустимой шириной векторизации, под которой мы будем понимать количество соседних итераций плоского цикла, независимых между собой.
Если максимально допустимая ширина векторизации оказывается ниже фактического значения, то вычисления необходимо производить с неполными масками, что приведет к деградации производительности).
При $k \ge 16$ можно параллельно выполнять 16 соседних итераций промежуточного цикла, при этом достигается максимальная плотность векторизации (показано зеленым цветом на схеме).
Все итерации промежуточного цикла разбиваются на группы по 16 соседних итераций и остаток, который векторизуется с шириной меньше 16 (показано желтым цветом, а в том случае, когда остаток состоит всего из одной итерации, то векторизация не применяется, что показано красным цветом на схеме).
При $1 < k < 16$ максимально допустимая ширина векторизации всегда меньше 16, к тому же, как и в предыдущем блоке, возможно появление невекторизуемого остатка.
При $k = 1$ имеет место невекторизуемая сортировка вставками.
Наличие участков кода с шириной векторизации менее 16 приводит к неоптимальному результирующему коду.

Функция \texttt{shell\_sort\_k\_i\_w}, появившаяся после декомпозиции алгоритма сортировки Шелла, содержит реализацию сортировки $w$ соседних срезов массива, взятых с шагом $k$.
Количество итераций внутреннего цикла при сортировке одного среза никак не связано с количеством итераций внутреннего цикла при сортировке соседнего среза.
Это является проявлением нерегулярности количества итераций внутреннего цикла.
Для объединения соседних итераций промежуточного цикла перепишем код сортировки среза в предикатной форме, после чего заменим все инструкции векторными аналогами, а предикаты –- векторными масками (см. рис.~\ref{fig:text_4_vec_irreg_shell_cfg}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_shell_cfg.pdf}
\singlespacing
\captionstyle{center}\caption{Схема перевода тела внутреннего цикла сортировки Шелла в предикатную форму.}
\label{fig:text_4_vec_irreg_shell_cfg}
\end{figure}

Если значения количества итераций соседних объединяемых циклов различаются сильно (а для сортировки Шелла это утверждение верно), то мы получаем потерю эффективности векторизации из за низкой плотности масок векторных инструкций (то есть малый процент элементов векторов на самом деле обрабатывается при выполнении векторной операции).
Векторизованная версия ядра сортировки Шелла представлена на листинге~\ref{lst:text_4_vec_irreg_shell_vec} и в \cite{iparGithub}.

\begin{lstlisting}[caption={Векторизованный вариант ядра сортировки Шелла.},label={lst:text_4_vec_irreg_shell_vec}]
void shell_sort_k_i_w(float *m, int n, int k, int i, int w)
{
    int j = i;
    __mmask16 ini_mask = ((unsigned int)0xFFFF) >> (16 - w);
    __mmask16 mask = ini_mask;
    __m512i ind_j = _mm512_add_epi32(_mm512_set1_epi32(i),
                                     ind_straight);
    __m512 t = _mm512_mask_load_ps(t, mask, &m[j]), q;

    do
    {
        mask = mask & _mm512_mask_cmp_epi32_mask(mask, ind_j, ind_k,
                                                 _MM_CMPINT_GE);
        q = _mm512_mask_load_ps(q, mask, &m[j - k]);
        mask = mask & _mm512_mask_cmp_ps_mask(mask, t, q,
                                              _MM_CMPINT_LT);
        _mm512_mask_store_ps(&m[j], mask, q);
        ind_j = _mm512_mask_sub_epi32(ind_j, mask, ind_j, ind_k);
        j -= k;
    }
    while (mask != 0x0);

    _mm512_mask_i32scatter_ps(m, ini_mask, ind_j, t, _MM_SCALE_4);
}
\end{lstlisting}

Также обратим внимание на медленную операцию scatter (листинг~\ref{lst:text_4_vec_irreg_shell_vec}, строка 23) -- векторный аналог операции записи в память из скалярного кода (листинг~\ref{lst:text_4_vec_irreg_shell}, строка 15) которая появилась также из-за нерегулярности количества итераций внутреннего цикла.
Кроме нее в векторизованном коде присутствуют команды обращения в память в общем случае по невыровненным адресам (так как в микропроцессорах Intel скорость обращения в память vmovaps не отличается от скорости обращения vmovups при условии выровненного обращения, то компилятор icc вовсе не генерирует инструкции vmovaps \cite{MOVUPSintel}).

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_shell_experimental_eff.pdf}
\singlespacing
\captionstyle{center}\caption{Ускорение векторизованной версии сортировки Шелла для различных последовательностей шагов.}
\label{fig:text_4_vec_irreg_eff}
\end{figure}

Для экспериментов на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-11} были использованы две версии исходного кода: скалярная функция сортировки и векторизованная с помощью функций-инстринсиков.
Обе версии сортировки были собраны компилятором icc с уровнем оптимизаии -O3.
На рис.~\ref{fig:text_4_vec_irreg_eff} представлены результаты экспериментальных запусков для замеров ускорения векторизованного кода для последовательностей шагов Шелла, Хиббарда и Сэджвика.
Результаты показали, что ускорение редко превышает отметку 2.

%\begin{figure}[ht]
%\centering
%\includegraphics[width=0.8\textwidth]{./pics/text_4_vec_irreg/pack.png}
%\singlespacing
%\captionstyle{center}\caption{Иллюстрация потери производительности для вложенного цикла с нерегуярным количеством итераций.}
%\label{fig:text_4_vec_irreg_pack}
%\end{figure}

Рассмотрим пример векторизации программного контекста с внутренним циклом с нерегулярным количеством итераций для целочисленного программного контекста -- программного кода, в котором преобладают целочисленные вычисления, а также ведется работа с дискретными структурами данных.
В качестве примера целочисленного программного контекста возьмем алгоритм декомпозиции графа с помощью пузырькового роста доменов.
Алгоритм пузырькового роста из раздела~\ref{sec:par_decompsurf_methods}, используемый в генетическом алгоритме декомпозиции графа, требует эффективной реализации, так как в составе генетического алгоритма он должен исполняться многократно для одного и того же графа, но с разными настройками декомпозиции, закодированными в генотипе декомпозиции.
Этот алгоритм работает с целочисленным программным контекстом и может быть векторизован с помощью векторных операций над упакованными целыми числами.

Рассмотрим возможности по ускорению алгоритма пузырьковго роста с помощью векторизации.
Пусть на вход в алгоритм подается граф, информация о его ребрах записана в массиве \texttt{inc}, где \texttt{inc[i]} –- массив номеров всех вершин, смежных с вершиной $i$.
Номера доменов, к которым относятся конкретные вершины хранятся в массиве \texttt{domains}.
В алгоритме пузырькового роста домены наращиваются последовательно с помощью алгоритма обхода графа в ширину, начиная от инициирующих вершин.
Структура \texttt{q} -- массив очередей вершин, ожидающих попадания в домены, в начале работы алгоритма очередь \texttt{q[i]} содержит только одну инициирующую вершину $i$-го домена.
В качестве масссива и очереди используются структуры STL vector и queue соответственно.
Пусть требуется выполнить декомпозицию (или раскраску вершин графа) на \texttt{domains\_count} доменов.
Тогда простейшая реализация алгоритма пузырькового роста доменов от инициирующих вершин может иметь следующий вид (см. листинг~\ref{lst:text_4_vec_integer}):

\begin{lstlisting}[caption={Реализация алгоритма пузырькового роста доменов.},label={lst:text_4_vec_integer}]
while (is_q)
{
    is_q = false;

    for (size_t c = 0; c < domains_count; ++c)
    {
        if (q[c].empty()) continue;

        is_q = true;
        n = q[c].front();
        q[c].pop();

        if (domains[n] == -1)
        {
            domains[n] = c;
            for (auto ngh : inc[n]) q[c].push(ngh);
        }
    }
}
\end{lstlisting}

Реализация алгоритма представляет собой гнездо из 3 циклов.
Внешний цикл выполняется до тех пор, пока найдется хотя бы одна непустая очередь домена.
Средний цикл выполнятся по номерам доменов.
Для каждого домена берется первая необработанная вершина из соответствующей очереди, и если она еще не отнесена ни к одному домену, то она заносится в текущий домен, а все ее соседи отправляются в очередь.
Внутренний цикл -- цикл по всем соседям только что обработанной вершины, которые должны быть занесены в очередь.
Будем выполнять векторизацию представленного кода по среднему циклу, и для простоты анализа приведем реализацию для фиксированного значения \texttt{domains\_count = 16} (это позволит избавиться от среднего цикла, и заменить его набором отдельных векторных операций).

Для выполнения векторизации вначале необходимо избавиться от STL\label{abbr:stl-1} структур vector и queue, так как они имеют свою внутреннюю реализацию, и векторизация операций по работе с ними невозможна.
Вместо структуры \texttt{vector<int>} будем хранить информацию о списке соседних вершин просто в массиве, 0-м элементом которого будет его размер.
Очередь queue также будет имитировать с помощью массива и индексов \texttt{front} и \texttt{back}, указывающих на первый и последний элементы очереди соответственно.
Тогда операция \texttt{push(v)} будет соответствовать записи в массив по индексу \texttt{back} с его продвижением, а операция \texttt{pop} будет соответствовать просто продвижению индекса \texttt{front}.
Очередь пуста если ее индекс \texttt{front} больше индекса \texttt{back}.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_genetic_code.pdf}
\singlespacing
\captionstyle{center}\caption{Векторизация программного кода алгоритма пузырькового роста путем замены скалярных инструкций векторными аналогами.}
\label{fig:text_4_vec_integer_code}
\end{figure}

На рис.~\ref{fig:text_4_vec_integer_code} представлены скалярная и векторная версии программного кода реализации алгоритма пузырькового роста.
Полная версия исходного кода доступна в \cite{comboptGithub}.
В векторной версии \texttt{ADD} обозначает функцию-интринсик \texttt{\_mm512\_mask\_add\_epi32}, \texttt{GTH} и \texttt{SCT} -- аналогично представляют собой краткие имена для интринсиков операций gather и scatter.
Обозначения \texttt{GTH2} и \texttt{SCT2} -- это те же операции \texttt{GTH} и \texttt{SCT}, только использующие сразу два смещения от базового адреса).
Цифрой <<1>> обозначена векторизация условия продолжения выполнения внешнего цикла (цикл завершает работу, если все очереди доменов пусты).
Цифрой <<2>> обозначена векторизация извлечения следующей вершины из каждой очереди.
Цифрой <<3>> обозначена проверка принадлежности извлеченных вершин к какому-либо домену (в векторной версии формируется маска \texttt{is\_no\_domain} -- маска с номерами доменов, в которые добавляется новая вершина).
Цифрой <<4>> обозначена векторизация помещения рассматриваемой вершины в текущий домен и получение количества ее соседей. 
Цифра <<5>> -- обработка всех соседей только что помещенной в домен вершины, и цифра <<6>> -- добавление этих соседей в очереди.

Для оценки эффективности векторизации были произведены запуски на дуальных графах поверхностных прямоугольных расчетных сеток со стороной от 20 до 2000 ячеек (то есть на графах с количеством вершин от 400 до 4 млн).
Замеры ускорения выполнялись на микропроцессоре Intel Xeon Phi KNL\label{abbr:knl-12}, результаты представлены на рис.~\ref{fig:text_4_vec_integer_sp}, для удобства приведен также график сглаженного показателя ускорения.

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{fig/vec_genetic_chart_speedup_rus.png}
\singlespacing
\captionstyle{center}\caption{Ускорение и эффективность векторизации алгоритма пузырькового роста в зависимости от размера стороны расчетной сетки.}
\label{fig:text_4_vec_integer_sp}
\end{figure}

Замеры ускорения продемонстрировали ускорение в диапазоне 1,7-2,2 раза для рассматриваемых графов с количеством ячеек от 400 до 4 млн.
Анализируя график сглаженного показателя ускорения, можно отметить, что максимум наблюдается при размере стороны расчетной сетки в районе 750 и равен примерно 1,95.
Снижение ускорения при уменьшении стороны расчетной сетки связано с увеличение количества конфликтов при обработке следующих вершин из очередей доменов.
Снижение ускорения при увеличении стороны расчетной сетки связано с увеличением разброса смещений при выполнении операций gather/scatter, что приводит к промахам в кэш-память.
Продемонстрированные невысокие результаты ускорения объясняются прежде всего нерегулярным количеством итераций циклов в гнезде, а также обилием операций множественного обращения в память gather/scatter.

%---------------------------------------------------------------------------------------------------
% Выводы.

\subsection{Выводы из главы}

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{fig/vec_map_cut.pdf}
\singlespacing
\captionstyle{center}\caption{Карта эффективности векторизации.}
\label{fig:text_4_fin_map}
\end{figure}

Векторизация является важной низкоуровневой оптимизацией программного кода, с помощью которой можно достичь кратного ускорения суперкомпьютерных приложений.
Наиболее перспективным набором векторных инструкций является набор AVX-512\label{abbr:avx-13}, с помощью которого можно векторизовать сложный программный контекст.

Рассмотрены и предложены новые методы векторизации программного кода.
На рис.~\ref{fig:text_4_fin_map} приведена карта сравнения программного контекста различного вида по эффективности векторизации $e_{vec}$.
На рисунке схожие по свойствам тестовые примеры объединены в одной цветовой гамме.
Многие из представленных тестовых примеров векторизации программного кода были использованы при численном решении задач обледенения и газовой динамики.

В разделе \ref{sec:text_4_small_matr} продемонстрированы подходы к векторизации матричных операций малой размерности.
Рассмотрены разные способы выделения однотипных операций и продемонстрирована потеря производительности из-за низкой плотности масок (см. риc.~\ref{fig:text_4_fin_map}, малоразмерные матрицы).

В разделе \ref{sec:text_4_flat} введено понятие плоского цикла, с помощью которого унифицируется объединение однотипных операций путем записи тела плоского цикла в предикатной форме с последущей заменой скалярных операций векторными аналогами.
Плоский цикл может быть векторизован при практически произвольном виде его тела (тело может содержать сложное управления, гнезда циклов, вызовы функций).
Приведено описание подхода, при котором вычисления могут быть представлены в виде композиции плоских циклов с относительно простым телом, после чего успешно векторизованы оптимизирующим компилятором в автоматическом режиме (см. рис.~\ref{fig:text_4_fin_map}, \texttt{calc\_fgh}, \texttt{calc\_d\_to\_u}, \texttt{calc\_u\_to\_d}).
Отмечено, что цикл, не являющийся в полной мере плоским (квазиплоский цикл), также может быть успешно векторизован, но с некоторой потерей производительности (см. рис.~\ref{fig:text_4_fin_map}, \texttt{calc\_flows}).

Так как основной преградой к эффективной векторизации является наличие операций передачи управления внутри тела плоского цикла, то в разделе \ref{sec:text_4_loc_branch} рассмотрена оптимизация, направленная на избавление от условий внутри цикла -- вынос маловероятного региона из цикла.
Поставлен эксперимент по определению эффективности автоматической векторизации при использовании этой оптимизации (см. рис.~\ref{fig:text_4_fin_map}, \texttt{flights\_safety}).

В разделе \ref{sec:vec_mrg} приведено описание и теоретическая оценка общего подхода к избавлению от операций передачи управления и слиянию путей исполнения в теле плоского цикла с помощью векторных инструкций blend.
Приведена операция проверки векторных масок на пустоту, которая оказывает наибольший прирост производительности при векторизации простого программного контекста (см. рис.~\ref{fig:text_4_fin_map}, функции с пометкой \texttt{check}).

В разделе \ref{sec:text_4_comb_mask} предложен метод объединения векторных масок, позволяющий одновременно исполнять блоки векторных инструкций с непересекающимися масками (см. рис.~\ref{fig:text_4_fin_map}, \texttt{prefun union}).
Предложен метод комбинирования векторных масок, позволяющий одновременно исполнять блоки векторных инструкций с пересекающимися масками.

В разделе~\ref{sec:vec_nests} приведен анализ эффективности гнезд циклов с разными свойствами внутреннего цикла.
Рассмотрены случаи внутренних циклов с постоянным (см. рис~\ref{fig:text_4_fin_map}, \texttt{tri\_box\_intersect}), непостоянным (см. рис.~\ref{fig:text_4_fin_map}, \texttt{starpu}) и нерегулярным (см. рис.~\ref{fig:text_4_fin_map}, циклы с нерегулярным количеством итераций) количеством итераций.
Наиболее сложным для векторизации случаем является векторизация гнезд циклов с нерегулярным количеством итераций.
Такой программный контекст характерен для дискретных задач и он демонстрирует наиболее низкую эффективность векторизации.

%---------------------------------------------------------------------------------------------------
